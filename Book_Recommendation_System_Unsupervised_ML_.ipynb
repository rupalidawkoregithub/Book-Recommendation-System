{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rupalidawkoregithub/Book-Recommendation-System/blob/main/Book_Recommendation_System_Unsupervised_ML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual Notebook\n",
        "##### **Team Member 1 -** Rupali Dawkore\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors.\n",
        "\n",
        "The main objective is to create a book recommendation system for users.\n",
        "\n",
        "Content\n",
        "The Book-Crossing dataset comprises 3 files.\n",
        "\n",
        "● Users\n",
        "\n",
        "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL values.\n",
        "\n",
        "● Books\n",
        "\n",
        "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in the case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavors (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon website.\n",
        "\n",
        "● Ratings\n",
        "\n",
        "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import re\n",
        "import pickle\n",
        "import operator\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# importing missingo library which helps us to visualize the missing values\n",
        "import missingno as msno\n",
        "# This is to supress the warning messages (if any) generated in our code\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive for access the dataset of Credit Card Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading datasets of Book Recommendation Systems \n",
        "#books_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Books.csv\")     # Read books csv file\n",
        "#users_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Users.csv\")     # Read users csv file\n",
        "#ratings_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Ratings.csv\") # Read ratings csv file\n",
        "books_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Books (1).csv\")     # Read books csv file\n",
        "users_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Users (1).csv\")     # Read users csv file\n",
        "ratings_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Ratings (2).csv\")     # Read users csv file"
      ],
      "metadata": {
        "id": "s8kUSQz_Krhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape of each dataframe \n",
        "print(\"Books Data:\", books_df.shape)        # Checked shape of books dataframe\n",
        "print(\"Books-ratings :\", ratings_df.shape)  # Checked shape of ratings dataframe\n",
        "print(\"Users Data:\", users_df.shape)        # Checked shape of users dataframe\n"
      ],
      "metadata": {
        "id": "u7ZL1fwoqrXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Books Dataset**"
      ],
      "metadata": {
        "id": "jyoxpEv81PkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "books_df.info() "
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', -1) "
      ],
      "metadata": {
        "id": "LieEliMHMeyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "ZF-yyObuFe4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows and columns\n",
        "rows, columns = books_df.shape "
      ],
      "metadata": {
        "id": "vkRi4VGHqReZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns\n",
        "print(\"Number of rows: \", rows)\n",
        "print(\"Number of columns: \", columns) "
      ],
      "metadata": {
        "id": "7JMoXvXxy3u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking all columns from books dataframe and looking forward the first 5 rows\n",
        "print(\"Columns: \", list(books_df.columns))\n",
        "books_df.head() "
      ],
      "metadata": {
        "id": "RVq2QTleLX8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dataset Information"
      ],
      "metadata": {
        "id": "nDEbkxCCF7Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_df.info() "
      ],
      "metadata": {
        "id": "IbGFrmNFKL65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Duplicate Values"
      ],
      "metadata": {
        "id": "cvQaDZDKGGT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in books dataset: {books_df.duplicated().sum()}\") "
      ],
      "metadata": {
        "id": "y0mPAHsMGHiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicate Values in Books Dataframe."
      ],
      "metadata": {
        "id": "0jEdfnOur6sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dropping Columns"
      ],
      "metadata": {
        "id": "MIFBxB30tG5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Unnecessary URL columns\n",
        "books_df.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
        "books_df.head() "
      ],
      "metadata": {
        "id": "cAy-w3C8Dh83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Missing Values/Null Values"
      ],
      "metadata": {
        "id": "wit8Xli6FqDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making function to check missing or null values of dataframes\n",
        "def missing_values(df): \n",
        "    mis_val=df.isnull().sum()\n",
        "    mis_val_percent=round(df.isnull().mean().mul(100),2)\n",
        "    mz_table=pd.concat([mis_val,mis_val_percent],axis=1)\n",
        "    mz_table=mz_table.rename(\n",
        "    columns={df.index.name:'col_name',0:'Missing Values',1:'% of Total Values'})\n",
        "    mz_table['Data_type']=df.dtypes\n",
        "    mz_table=mz_table.sort_values('% of Total Values',ascending=False)\n",
        "    return mz_table.reset_index()"
      ],
      "metadata": {
        "id": "_KsxjKfCLndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values for books dataframe\n",
        "missing_values(books_df) "
      ],
      "metadata": {
        "id": "k80Br5v8HGn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(books_df,figsize=(10,5), color=\"tab:cyan\") "
      ],
      "metadata": {
        "id": "_fA1hx7VeUMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have missing value in Book-Author & Publisher.   "
      ],
      "metadata": {
        "id": "AKPqz5Gzt7Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Index of null values \n",
        "books_df.loc[books_df['Book-Author'].isnull(),:] "
      ],
      "metadata": {
        "id": "jKqs_iqhLvvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing value of book author with other\n",
        "books_df.at[187689 ,'Book-Author'] = 'Others' "
      ],
      "metadata": {
        "id": "36DsZimLC_pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Index of null values \n",
        "books_df.loc[books_df['Publisher'].isnull(),:] "
      ],
      "metadata": {
        "id": "OOwFtwJVL1pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing value of publisher with other\n",
        "books_df.at[128890 ,'Publisher'] = 'Others'\n",
        "books_df.at[129037 ,'Publisher'] = 'Others' "
      ],
      "metadata": {
        "id": "sRUh8CVBDKMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "eXoI3BkWt7pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "books_df.columns "
      ],
      "metadata": {
        "id": "W7m_uzKEt7pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe \n",
        "books_df.describe()"
      ],
      "metadata": {
        "id": "nWDJrhqFt7pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variables Description "
      ],
      "metadata": {
        "id": "wv-Kj_MSt7pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "XSrxp_3Mt7pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "Qx-I1JoqvPKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking for columns in Books dataset\n",
        "books_df.columns "
      ],
      "metadata": {
        "id": "CpU3SkBrvPKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for printing the Unique Values of Each column in dataframe\n",
        "def get_all_unique_values(df):\n",
        "    for col in df.columns:\n",
        "        print(f\"Unique values in column '{col}':\")\n",
        "        print(df[col].unique()) \n",
        "        print()"
      ],
      "metadata": {
        "id": "qHXJfZbGgWsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(books_df) "
      ],
      "metadata": {
        "id": "P4yfO0xWgr71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique values for column Year-of-publication\n",
        "books_df['Year-Of-Publication'].unique() "
      ],
      "metadata": {
        "id": "K4zTmBpaMI6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the values of DK Publishing Inc\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'DK Publishing Inc',:] "
      ],
      "metadata": {
        "id": "gpKLjJVNzcOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the values of Gallimard\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'Gallimard',:] "
      ],
      "metadata": {
        "id": "2ojtr41OzllM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As it can be seen from above that there are some incorrect entries in Year-Of-Publication field. It looks like Publisher names 'DK Publishing Inc' and 'Gallimard' have been incorrectly loaded as Year-Of-Publication in dataset due to some errors in csv file.**"
      ],
      "metadata": {
        "id": "Dk_18Opez1KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From above, it is seen that bookAuthor is incorrectly loaded with Year-Of-Publication, hence making required corrections\n",
        "#ISBN '078946697X'\n",
        "books_df.at[209538 ,'Publisher'] = 'DK Publishing Inc'\n",
        "books_df.at[209538 ,'Year-Of-Publication'] = 2000\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Author'] = 'Michael Teitelbaum' "
      ],
      "metadata": {
        "id": "Z0cHIOlp4aKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ISBN '0789466953'\n",
        "books_df.at[221678 ,'Publisher'] = 'DK Publishing Inc'\n",
        "books_df.at[221678 ,'Year-Of-Publication'] = 2000\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Author'] = 'James Buckley' "
      ],
      "metadata": {
        "id": "OhCVxHwh5CnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ISBN '2070426769'\n",
        "books_df.at[220731 ,'Publisher'] = 'Gallimard'\n",
        "books_df.at[220731 ,'Year-Of-Publication'] = 2003\n",
        "books_df.at[209538 ,'Book-Title'] = 'Peuple du ciel - Suivi de Les bergers '\n",
        "books_df.at[209538 ,'Book-Author'] = 'Jean-Marie Gustave Le ClÃ?Â©zio'"
      ],
      "metadata": {
        "id": "kBtZnPFOBE1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert \"Fee\" from String to int\n",
        "books_df= books_df.astype({'Year-Of-Publication':'int'})\n",
        "print(books_df.dtypes)"
      ],
      "metadata": {
        "id": "cIbCrlpZd3SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df[\"Year-Of-Publication\"].shape"
      ],
      "metadata": {
        "id": "ASD_1IIQBg0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df['Year-Of-Publication'].unique() "
      ],
      "metadata": {
        "id": "neypbWfzCPKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_years = sorted(books_df['Year-Of-Publication'].unique())\n",
        "print(sorted_years)"
      ],
      "metadata": {
        "id": "rvAOXsgB5QzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Year-Of-Publication' column in the dataset is of integer type, with values ranging from 0 to 2050. However, as the dataset was created in 2004, it is assumed that all years after 2006 are invalid, allowing for a margin of two years in case the dataset was updated. Any invalid entries in this column, including those with a value of 0, will be converted to NaNs using a boolean mask. Afterward, the remaining valid values in the column will be used to calculate the median year. Finally, all NaN values in the column will be replaced with the calculated median year. This process ensures that the data is clean and usable for analysis."
      ],
      "metadata": {
        "id": "IJ89AS8Zz-Jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The value 0 for Year-Of_Publication is invalid and as this dataset was published in 2004, We have assumed that the years after 2006 to be invalid and setting invalid years as NaN**"
      ],
      "metadata": {
        "id": "wgjDvbQIPeSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace values greater than 2006 or equal to 0 with NaN\n",
        "# books_df.loc[(books_df['Year-Of-Publication'] > 2004) | (books_df['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "# # Fill NaN values with the median value of the column\n",
        "# books_df['Year-Of-Publication'].fillna(round(books_df['Year-Of-Publication'].median()), inplace=True) "
      ],
      "metadata": {
        "id": "ZC9qzYQiTg86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert invalid values to NaN\n",
        "mask = (books_df['Year-Of-Publication'] > 2004) | (books_df['Year-Of-Publication'] == 0)\n",
        "books_df.loc[mask, 'Year-Of-Publication'] = np.nan\n",
        "\n",
        "# Replace NaN values with median of remaining valid values\n",
        "median_year = books_df['Year-Of-Publication'].median()\n",
        "books_df['Year-Of-Publication'].fillna(median_year, inplace=True) "
      ],
      "metadata": {
        "id": "0DTiWk1XktXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking unique values for year of publication\n",
        "books_df['Year-Of-Publication'].unique()   "
      ],
      "metadata": {
        "id": "fgksxf4GUxBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Users Dataset**"
      ],
      "metadata": {
        "id": "-u_UUJTXA2As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Users Dataset First Look"
      ],
      "metadata": {
        "id": "6JLEi5NypRj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Dataset First Look\n",
        "users_df.head()     "
      ],
      "metadata": {
        "id": "7lRMjR0tpXs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(users_df) \n"
      ],
      "metadata": {
        "id": "H1KzSCNimjDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "wr9GHBn9IDUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "row,columns=users_df.shape\n",
        "print(\"Rows of Users Df\",row) \n",
        "print(\"Columns of Users Df\",columns)   "
      ],
      "metadata": {
        "id": "SNl5B5EgH9io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Information"
      ],
      "metadata": {
        "id": "Ki2iHS9DBQRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.info()    "
      ],
      "metadata": {
        "id": "ew_tBumhBFpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This dataset consists of 3 features with 278858 entries with 'Age' column having Null Values."
      ],
      "metadata": {
        "id": "26sbLlu510kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age Column have lots of Null Values"
      ],
      "metadata": {
        "id": "sv4Zf1-T11wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Duplicate Values"
      ],
      "metadata": {
        "id": "aCrWQECDI1cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in users dataset: {users_df.duplicated().sum()}\")   "
      ],
      "metadata": {
        "id": "fWp_v9T9Iq2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicates found."
      ],
      "metadata": {
        "id": "Mlap18Wr2ZnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "uuYKE9l5FTVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "users_df.columns   "
      ],
      "metadata": {
        "id": "F3lgsbH1FTVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "users_df.describe()  "
      ],
      "metadata": {
        "id": "IqPpC47gFTVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "-SSWLLg8FTVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ODhXQjYZFTVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "CRFmQcS43XgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking for columns in users dataset\n",
        "users_df.columns  "
      ],
      "metadata": {
        "id": "7XSkuEZSFTVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(users_df) "
      ],
      "metadata": {
        "id": "ANGR1LDfJO6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "cZzvpJJ8I6Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "JewEHUVMIpLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age have around 39% missing values.**"
      ],
      "metadata": {
        "id": "bwFqsjhSL0YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(users_df,figsize=(10,5), color=\"tab:blue\") "
      ],
      "metadata": {
        "id": "oH4IMNNadzVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for all values present in Age column\n",
        "users_df['Age'].unique()   "
      ],
      "metadata": {
        "id": "za08vVjCJSeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of Age column\n",
        "plt.figure(figsize=(8,4)) \n",
        "sns.distplot(users_df['Age']); "
      ],
      "metadata": {
        "id": "La-9uDZC4C86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The feature Age is Rightly skewed. Replacing Null values with Median value"
      ],
      "metadata": {
        "id": "_qnopkHp4k-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(list(users_df['Age'].unique())))   "
      ],
      "metadata": {
        "id": "Nh49v-pJJxZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the values that there are people who are 0 years old and also we have people who are 244 years old which is for sure an error so we will keep the age group only from 5 years old to 85 years old and for the rest we will replace them with mean of the age."
      ],
      "metadata": {
        "id": "0PCnTi7nPSUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the less than 5 and more than 85 values with mean of the age   \n",
        "# users_df.loc[(users_df['Age'] < 5) | (users_df['Age'] > 100),'Age'] = np.nan\n",
        "# users_df['Age'].fillna((users_df['Age'].median()), inplace=True)    "
      ],
      "metadata": {
        "id": "E4ZOJ_V5PU-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert invalid values to NaN\n",
        "masking= (users_df['Age'] > 100) | (users_df['Age'] < 5)\n",
        "users_df.loc[masking, 'Age'] = np.nan\n",
        "\n",
        "# Replace NaN values with median of remaining valid values\n",
        "median_age = users_df['Age'].median()\n",
        "users_df['Age'].fillna(median_age, inplace=True)"
      ],
      "metadata": {
        "id": "20MvZfiiTv6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking unique values for age columns\n",
        "print(sorted(users_df['Age'].unique())) "
      ],
      "metadata": {
        "id": "G57bWb2mQT0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rehecking the null values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "G4rYQMn86FVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* No Null values are present in Age column."
      ],
      "metadata": {
        "id": "67-7wH-L6TJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "lq9PpQz97A5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "VQB4x5RS7A5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for outliers in age column"
      ],
      "metadata": {
        "id": "LQwMOq2I9tUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(y='Age', data=users_df)\n",
        "plt.title('Find outlier data in Age column') "
      ],
      "metadata": {
        "id": "tqEdltEC8ecj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking location with unique \n",
        "users_df.Location.unique() "
      ],
      "metadata": {
        "id": "yQxDZlK18utX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of unique values for location \n",
        "users_df.Location.nunique() "
      ],
      "metadata": {
        "id": "jd8nC_Nc86q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**57339 unique Value it's really hard to understand,\n",
        "So lets create column Country.**"
      ],
      "metadata": {
        "id": "ulFLrZCt86h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_country(users_df):\n",
        "#     users_df['Country'] = users_df['Location'].str.extract(r',\\s?(\\w+\\s*\\w*)\\\"*$')\n",
        "#     return users_df   "
      ],
      "metadata": {
        "id": "5vW33Mzr7475"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_country(location):\n",
        "    pattern = r',\\s?(\\w+\\s?\\w*)\\\"*$'\n",
        "    match = re.search(pattern, location)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "users_df['Country'] = users_df['Location'].apply(extract_country)"
      ],
      "metadata": {
        "id": "12zo9Ge1oBc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract_country(users_df) "
      ],
      "metadata": {
        "id": "GSZA_io9WwjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.Country.nunique()  "
      ],
      "metadata": {
        "id": "2OAo5Cf-9UNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop location column\n",
        "users_df.drop('Location',axis=1,inplace=True)  "
      ],
      "metadata": {
        "id": "XxRZZP1x9XfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.head(2)  "
      ],
      "metadata": {
        "id": "6Y9F6_we9acb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking missing values of users dataframe\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "KSUbdEc3_K3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_df['Country']=users_df['Country'].astype('str') "
      ],
      "metadata": {
        "id": "tSG704Rp-fmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(users_df['Country'])  "
      ],
      "metadata": {
        "id": "QtuvR2ieYIVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(users_df['Country'][:10])  "
      ],
      "metadata": {
        "id": "Y8MEG7J4Ywxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Replace some Misspelt Countries \n",
        "users_df['Country'].replace(['','01776','02458','19104','23232','30064','85021','87510','alachua','america','austria',\n",
        "                             'autralia','cananda','geermany','germay','italia','united kindgonm','united sates','united staes',\n",
        "                             'united state','united states','us','urugua','indiai','canada eh','le canada','nan'],\n",
        "                           ['others','usa','usa','usa','usa','usa','usa','usa','usa','usa','australia','australia',\n",
        "                            'canada','germany','germany','italy','united kingdom','usa','usa','usa','usa','usa',\n",
        "                            'uruguay','india','canada','canada','others'],inplace=True)  "
      ],
      "metadata": {
        "id": "yYleBvQPAx8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['Country'].fillna('other',inplace=True)  "
      ],
      "metadata": {
        "id": "42AT4SyQva8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.head() "
      ],
      "metadata": {
        "id": "FkSk3o9Kvfw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking missing values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "I1T9U5V_BsoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.shape "
      ],
      "metadata": {
        "id": "TKqECxOcYRL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ratings Dataset**"
      ],
      "metadata": {
        "id": "TJa5lrQ7XGsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Ratings Dataset First Look"
      ],
      "metadata": {
        "id": "OmWyatIDaywj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first look for rating dataset\n",
        "ratings_df.head()   "
      ],
      "metadata": {
        "id": "CxvhHYaPazpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.shape "
      ],
      "metadata": {
        "id": "uOosAGfgYvGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "row,col=ratings_df.shape\n",
        "print(\"Row:\",row)\n",
        "print(\"col:\",col)   "
      ],
      "metadata": {
        "id": "5w2Or4LgbJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking all columns from ratings dataframe\n",
        "print(\"Columns: \", list(ratings_df.columns))  "
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "ratings_df.info()  "
      ],
      "metadata": {
        "id": "VXWfsYOQXaah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is No Null Values in the above dataset"
      ],
      "metadata": {
        "id": "nohbjzWPbyLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in ratings dataset: {ratings_df.duplicated().sum()}\")  "
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicates found."
      ],
      "metadata": {
        "id": "RZExT0xycQmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "PFhG6faacRDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "ratings_df.columns  "
      ],
      "metadata": {
        "id": "M0r_4aRAcRDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "ratings_df.describe()  "
      ],
      "metadata": {
        "id": "Iprg8h5bcRDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "36CT4-9LcRDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "N-VCyy8ecRDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "lhUV7qMudDYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values \n",
        "get_all_unique_values(ratings_df) "
      ],
      "metadata": {
        "id": "k1VngYhrdDYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values of ratings dataframe\n",
        "missing_values(ratings_df)  "
      ],
      "metadata": {
        "id": "R2mYGE54__0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(ratings_df,figsize=(10,5), color=\"tab:green\")  "
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "3i-XShTedDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "wE2UFjvwdDYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.head(1)  "
      ],
      "metadata": {
        "id": "2GMEdilwCXTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ratings dataset should have books only which exist in our books dataset.**"
      ],
      "metadata": {
        "id": "1MoRd4JyChp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only the records of ratings for the books and users whose data is there in the respective users and books csv file\n",
        "#ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]         # Filter ratings to only include ISBN present in books_df \n",
        "#ratings_df = ratings_df[ratings_df['User-ID'].isin(users_df['User-ID'])] # Filter ratings to only include users present in users_df\n"
      ],
      "metadata": {
        "id": "TIUFAy-BTBUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter ratings to only include ISBN present in books_df\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
        "\n",
        "# Filter ratings to only include users present in users_df\n",
        "ratings_df = ratings_df[ratings_df['User-ID'].isin(users_df['User-ID'])]"
      ],
      "metadata": {
        "id": "6WQSGl2XiSU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter ratings to only include users present in users_df\n",
        "#ratings_df = ratings_df[ratings_df['User-ID'].isin(users_df['User-ID'])]"
      ],
      "metadata": {
        "id": "E5uT9xQmI0Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.head() "
      ],
      "metadata": {
        "id": "Ms_J-YOGUqcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.info() "
      ],
      "metadata": {
        "id": "4Px3kQntTe4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.shape "
      ],
      "metadata": {
        "id": "IC5rOjYNhw4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we have 1149780 shape of ratings df now after manupulation  we have 1031136 that means some values are dropped."
      ],
      "metadata": {
        "id": "ZVP7C8b8amcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that no new user was there in ratings dataset."
      ],
      "metadata": {
        "id": "BxPfPHKOEiD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hence segragating implicit and explict ratings datasets\n",
        "ratings_df_explicit = ratings_df[ratings_df['Book-Rating'] != 0]  # In explicit we will take only that is not equal to 0\n",
        "ratings_df_implicit = ratings_df[ratings_df['Book-Rating'] == 0]  # In implicit we will take only that is equal to 0 "
      ],
      "metadata": {
        "id": "WIzwBQlMMiJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After Explicit and Implicit Dataset Shape \n",
        "print('ratings_explicit dataset shape',ratings_df_explicit.shape)\n",
        "print('ratings_implicit dataset',ratings_df_implicit.shape) "
      ],
      "metadata": {
        "id": "QaxFv6E-WfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking first five rows for rating_df_explicit \n",
        "ratings_df_explicit.head()  "
      ],
      "metadata": {
        "id": "dNh7dE5ybi5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute average rating for each book (ISBN)\n",
        "book_ratings = ratings_df_explicit.groupby('ISBN')['Book-Rating'].mean()\n",
        "# Create a new column 'Avg_Rating' and set its values to the corresponding average rating for each book\n",
        "ratings_df_explicit['Avg_Rating'] = ratings_df_explicit['ISBN'].map(book_ratings) "
      ],
      "metadata": {
        "id": "6BCQSMwisa9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating average \n",
        "#ratings_df_explicit['Avg_Rating']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('mean') \n",
        "# Create column Rating sum\n",
        "#ratings_df_explicit['Total_No_Of_Users_Rated']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "C-0EAH2ViidQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df_explicit.head()   "
      ],
      "metadata": {
        "id": "6prAG_i-jz6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Merging All Dataset.**"
      ],
      "metadata": {
        "id": "A2FFabo_kQdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating final dataframe  \n",
        "Final_df = users_df.copy()                                        # Copy users_df\n",
        "Final_df = pd.merge(Final_df,ratings_df_explicit,on='User-ID')    # Merge ratings_df_explicit on User-ID with final_df  \n",
        "Final_df = pd.merge(Final_df,books_df,on='ISBN')                  # Merge books_df on ISBN with final_df "
      ],
      "metadata": {
        "id": "72toQhqRkLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df.shape "
      ],
      "metadata": {
        "id": "k0KyS3_zINRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking first view of final dataframe\n",
        "Final_df.head()"
      ],
      "metadata": {
        "id": "6l00JjmCloCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df.info()     "
      ],
      "metadata": {
        "id": "XrSU0y_xgaOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(Final_df) "
      ],
      "metadata": {
        "id": "IoKrPPvtltGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df['Country'].unique() "
      ],
      "metadata": {
        "id": "kDrAwLpcrTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(Final_df) "
      ],
      "metadata": {
        "id": "lSRuptSF4ldn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df['Year-Of-Publication'].min() "
      ],
      "metadata": {
        "id": "W3icqsfN5BjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df['Year-Of-Publication'].max() "
      ],
      "metadata": {
        "id": "WvBCDkiz40GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Univariate**"
      ],
      "metadata": {
        "id": "h4Fp5XHtEXXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Distribution of Age and Rating**"
      ],
      "metadata": {
        "id": "2RyteUBNGH-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df = Final_df.copy()"
      ],
      "metadata": {
        "id": "OKbNTRaft17R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df.head()"
      ],
      "metadata": {
        "id": "5Gxi-Z8cuHku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Distribtuion of age column\n",
        "sns.distplot(Eda_df.Age)\n",
        "plt.title('Age Distribution Plot')"
      ],
      "metadata": {
        "id": "kJKGl3iY95L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df.Age.hist(bins=[0, 10, 20, 30, 40, 50,60,70,80])\n",
        "plt.title('Age Distribution\\n')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ic2CGacB7oPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The most active users are among those in their 30–40s.**"
      ],
      "metadata": {
        "id": "wfwLuBzr8LYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the ratings are distributed"
      ],
      "metadata": {
        "id": "R8e7_ekgEjLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Distribution for Ratings\n",
        "plt.rc(\"font\", size=10)\n",
        "Eda_df['Book-Rating'].value_counts(sort=False).plot(kind='bar')\n",
        "plt.title('Rating Distribution\\n')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uo168YD2EmcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ratings are very unevenly distributed, and the vast majority of ratings are 0 .As quoted in the description of the dataset - BX-Book-Ratings contains the book rating information. Ratings are either explicit, expressed on a scale from 1-10 higher values denoting higher appreciation, or implicit, expressed by 0.Hence segragating implicit and explict ratings datasets.**"
      ],
      "metadata": {
        "id": "fvm6MkVKFbhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Distribution of Explicit Rating**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NxpHFJggGhTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=ratings_df_explicit , x='Book-Rating', palette='rocket_r')"
      ],
      "metadata": {
        "id": "AAWfPsRzbQvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most books are rated 8, if we exclude the books, which are implicitly rated."
      ],
      "metadata": {
        "id": "mn0tg6VG3IgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bivariate**"
      ],
      "metadata": {
        "id": "JVyNjioAjLlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**To analyze the distribution of book ratings across Top 10 Countries and test for differences between Top Countries.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNp227UfjeDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the top 10 countries based on the number of ratings\n",
        "top_countries = Eda_df[\"Country\"].value_counts().head(10).index.tolist()\n",
        "\n",
        "# Filter the data to include only the top 10 countries\n",
        "df_top_countries = Eda_df[Eda_df[\"Country\"].isin(top_countries)]\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Create a box plot for each of the top countries\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.boxplot(x=\"Country\", y=\"Book-Rating\", data=df_top_countries, \n",
        "            order=top_countries, palette=\"Set3\", \n",
        "            width=0.5, fliersize=3, linewidth=1,\n",
        "            saturation=0.8)\n",
        "\n",
        "# Test for differences between the top countries\n",
        "grouped_data = [df_top_countries[df_top_countries[\"Country\"] == c][\"Book-Rating\"].values for c in top_countries]\n",
        "statistic, p_value = stats.kruskal(*grouped_data)\n",
        "\n",
        "print(\"Kruskal-Wallis H test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aClZKA0U7aw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway "
      ],
      "metadata": {
        "id": "NGQDxX_bjRbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by country and count the number of ratings for each country\n",
        "country_counts = Eda_df.groupby('Country')['Book-Rating'].count()\n",
        "\n",
        "# Select the top 10 countries by number of ratings\n",
        "top_countries = country_counts.sort_values(ascending=False).head(10).index\n",
        "\n",
        "# Filter the dataframe to only include rows for the selected countries\n",
        "df_top = Eda_df[Eda_df['Country'].isin(top_countries)]\n",
        "\n",
        "# Create a histogram of book ratings by country\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "for country in df_top['Country'].unique():\n",
        "    ax.hist(df_top[df_top['Country'] == country]['Book-Rating'], alpha=0.5, label=country)\n",
        "ax.set_xlabel('Book Rating')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Test for differences in book ratings between countries using ANOVA\n",
        "f_statistic, p_value = f_oneway(*[group['Book-Rating'] for name, group in df_top.groupby('Country')])\n",
        "\n",
        "print(\"F-Statistic: {:.2f}\".format(f_statistic))\n",
        "print(\"P-value: {:.5f}\".format(p_value))\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Steps**\n",
        "* Groups the data by country and counts the number of book ratings for each country using the groupby method and the count function.\n",
        "* Top 10 countries with the highest number of book ratings using the sort_values and head methods.\n",
        "* Filters the original dataframe Final_df to only include rows for the selected countries.\n",
        "* Histogram of book ratings by country for the selected top 10 countries.\n",
        "* Tests for differences in book ratings between the selected countries using ANOVA."
      ],
      "metadata": {
        "id": "qJ-o-liJoFCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram chart was chosen because it effectively displays the distribution of book ratings across countries. It allows us to see the frequency distribution of book ratings for each country. By using different colors for each country, we can also compare the distributions between countries.\n",
        "We can also identify any potential outliers or skewness in the data, which may affect our analysis."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of book ratings by country shows the distribution of book ratings for the top 10 countries. \n",
        "It appears that the majority of ratings fall between 0 and 10, with some variation between countries. \n",
        "The ANOVA test indicates that there is a statistically significant difference in book ratings between the top 10 countries. \n",
        "The relatively low **p-value suggests that the null hypothesis** (i.e., there is no difference in book ratings between countries) can be rejected, and that there are indeed differences in book ratings among the top 10 countries. \n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after analyzing the book ratings by country, we can identify which countries have the most active readers and what book rating preferences they have.\n",
        "This information can help businesses in the publishing industry tailor their marketing strategies to target these specific countries and offer books that are more likely to receive higher ratings. \n",
        "This can ultimately lead to increased sales and revenue.\n",
        "\n",
        "There are no insights from the analysis that necessarily lead to negative growth. \n",
        "The purpose of the analysis is to gain insights into book ratings by country, and the results are neutral in nature. \n",
        "The potential negative impact could only arise if a business ignores the insights gained from the analysis and fails to tailor their marketing strategies to target specific countries or fails to offer books that align with the book rating preferences of readers in those countries."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**List of publishers whose books tend to receive higher ratings.**"
      ],
      "metadata": {
        "id": "7fWiMWu362Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the average rating for each publisher\n",
        "publisher_ratings = Eda_df.groupby('Publisher')['Book-Rating'].mean()\n",
        "\n",
        "# Get the top 10 publishers with the highest average rating\n",
        "top_publishers = publisher_ratings.nlargest(10)\n",
        "\n",
        "# Create a bar chart of the top publishers and their average ratings\n",
        "plt.bar(top_publishers.index, top_publishers.values,color=['#ff9966'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Top 10 Publishers by Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bWOe2DISY5uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df.info()"
      ],
      "metadata": {
        "id": "1B4RWwHV05Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df.head()"
      ],
      "metadata": {
        "id": "4WrM8UVW1lTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**List of authors whose books tend to receive higher ratings.**"
      ],
      "metadata": {
        "id": "qIxMSzuAfMTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the average rating for each author\n",
        "author_ratings = Eda_df.groupby('Book-Author')['Book-Rating'].mean()\n",
        "\n",
        "# Get the top 10 authors with the highest average rating\n",
        "top_authors = author_ratings.nlargest(10)\n",
        "\n",
        "# Create a bar chart of the top authors and their average ratings\n",
        "plt.bar(top_authors.index, top_authors.values,color=['#669999'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Top 10 Authors by Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8BQQnFqYdZuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multivariate**"
      ],
      "metadata": {
        "id": "GZ_NGGye63gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ratings of popular books compare to those of less popular books, and does this vary by age group**"
      ],
      "metadata": {
        "id": "C0IcDpoDwiFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column for the age group based on the age of the user\n",
        "# def get_age_group(age):  \n",
        "#     if age < 18:\n",
        "#         return 'Under 18'\n",
        "#     elif age < 30:\n",
        "#         return '18-29'\n",
        "#     elif age < 40:\n",
        "#         return '30-39'\n",
        "#     elif age < 50:\n",
        "#         return '40-49'\n",
        "#     elif age < 60:\n",
        "#         return '50-59'\n",
        "#     else:\n",
        "#         return '60+'\n",
        "\n",
        "# Eda_df['Age Group'] = Eda_df['Age'].apply(get_age_group)  # Add Age Group column in Popularity_df"
      ],
      "metadata": {
        "id": "RVTd7hLTn_wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating sum\n",
        "# Eda_df['Total_No_Of_Users_Rated']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "bFeUusOMwHkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define popularity based on total number of users who rated the book\n",
        "# Eda_df['Popularity'] = Eda_df['Total_No_Of_Users_Rated'].apply(lambda x: 'Popular' if x > 50 else 'Less Popular')  "
      ],
      "metadata": {
        "id": "3Jk4oyBjjvZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by popularity and get the average rating for each group\n",
        "# popularity_ratings = Eda_df.groupby('Popularity')['Book-Rating'].mean()\n",
        "# popularity_ratings   "
      ],
      "metadata": {
        "id": "Hh8MbikjkM4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by popularity and age group and get the average rating for each group\n",
        "# popularity_age_ratings = Eda_df.groupby(['Popularity', 'Age Group'])['Avg_Rating'].mean().reset_index() "
      ],
      "metadata": {
        "id": "HV-7XTdS1qej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) \n",
        "\n",
        "# # Create the bar chart of popularity ratings\n",
        "# sns.barplot(x='Popularity', y='Avg_Rating', data=popularity_age_ratings, ax=ax1)\n",
        "# ax1.set_ylabel('Average Rating')\n",
        "# ax1.set_title('Average Rating by Book Popularity',fontsize=17) \n",
        "\n",
        "# # Create the box plot of the average ratings by age group\n",
        "# sns.boxplot(x='Age Group', y='Avg_Rating', hue='Popularity', data=Eda_df, ax=ax2)\n",
        "# ax2.set_title('Distribution of Ratings by Age Group and Book Popularity',fontsize=17)\n",
        "# ax2.set_xlabel('Age Group')\n",
        "# ax2.set_ylabel('Book Rating')\n",
        "# # Remove the legend box\n",
        "# ax2.legend_.remove()\n",
        "# # Adjust the spacing between the subplots\n",
        "# plt.subplots_adjust(wspace=0.3)\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "3WHlyO1rs5dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Eda_df.info()"
      ],
      "metadata": {
        "id": "4Q8uWLYKufpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(Eda_df)"
      ],
      "metadata": {
        "id": "N_OQ0osbx09D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Popularity_df['User-ID'].value_counts()[:10]"
      ],
      "metadata": {
        "id": "ZQxure3n9z3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df.shape "
      ],
      "metadata": {
        "id": "1xYyCcJzFTFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "missing_values(Final_df)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Final_df.info() "
      ],
      "metadata": {
        "id": "zwhJtjBdCyv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Content_based_df = Final_df.copy()\n",
        "Content_based_df.head() "
      ],
      "metadata": {
        "id": "gibIyhMUHrHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "jABQX8PfuWsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def content_based_recommender(book_title):\n",
        "    \n",
        "#     book_title = str(book_title)\n",
        "#     if book_title in Content_based_df['Book-Title'].values:\n",
        "#         rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts())\n",
        "#         rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index\n",
        "#         common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]\n",
        "        \n",
        "#         if book_title in rare_books:\n",
        "            \n",
        "#             random = pd.Series(common_books['Book-Title'].unique()).sample(2).values\n",
        "#             print('There are no recommendations for this book')\n",
        "#             print('Try: \\n')\n",
        "#             print('{}'.format(random[0]),'\\n')\n",
        "#             print('{}'.format(random[1]),'\\n')\n",
        "        \n",
        "#         else:\n",
        "            \n",
        "#             common_books = common_books.drop_duplicates(subset=['Book-Title'])\n",
        "#             common_books.reset_index(inplace= True)\n",
        "#             common_books['index'] = [i for i in range(common_books.shape[0])]\n",
        "#             target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "#             common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
        "#             cv = CountVectorizer()\n",
        "#             count_matrix = cv.fit_transform(common_books['combined_features'])\n",
        "#             cosine_sim = cosine_similarity(count_matrix)\n",
        "#             index = common_books[common_books['Book-Title'] == book_title]['index'].values[0]\n",
        "#             sim_books = list(enumerate(cosine_sim[index]))\n",
        "#             sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
        "#                                       reverse=True)[1:6]\n",
        "            \n",
        "#             book_titles = []\n",
        "#             authors = []\n",
        "#             publishers = []\n",
        "#             for i in range(len(sorted_sim_books)):\n",
        "#                 book_title = common_books[common_books['index'] == sorted_sim_books[i][0]]['Book-Title'].item()\n",
        "#                 author = common_books[common_books['index'] == sorted_sim_books[i][0]]['Book-Author'].item()\n",
        "#                 publisher = common_books[common_books['index'] == sorted_sim_books[i][0]]['Publisher'].item()\n",
        "#                 book_titles.append(book_title)\n",
        "#                 authors.append(author)\n",
        "#                 publishers.append(publisher)\n",
        "            \n",
        "#             return book_titles, authors, publishers\n",
        "        \n",
        "#     else:\n",
        "        \n",
        "#         print('Cant find book in dataset, please check spelling')\n"
      ],
      "metadata": {
        "id": "YOf6bmHt1IpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# titles, authors, publishers = content_based_recommender(\"Harry Potter and the Sorcerer's Stone (Book 1)\")\n",
        "# titles"
      ],
      "metadata": {
        "id": "dTW6D4Y71MU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def content_based_recommender(book_title, basis=None):\n",
        "    \n",
        "#     book_title = str(book_title)\n",
        "#     if book_title in Content_based_df['Book-Title'].values:\n",
        "#         rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts())\n",
        "#         rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index\n",
        "#         common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]\n",
        "        \n",
        "#         if book_title in rare_books:\n",
        "            \n",
        "#             random = pd.Series(common_books['Book-Title'].unique()).sample(2).values\n",
        "#             print('There are no recommendations for this book')\n",
        "#             print('Try: \\n')\n",
        "#             print('{}'.format(random[0]),'\\n')\n",
        "#             print('{}'.format(random[1]),'\\n')\n",
        "        \n",
        "#         else:\n",
        "            \n",
        "#             common_books = common_books.drop_duplicates(subset=['Book-Title'])\n",
        "#             common_books.reset_index(inplace= True)\n",
        "#             common_books['index'] = [i for i in range(common_books.shape[0])]\n",
        "            \n",
        "#             if basis is not None:\n",
        "#                 target_cols = ['Book-Title', basis]\n",
        "#                 common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
        "#             else:\n",
        "#                 target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "#                 common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
        "                \n",
        "#             cv = CountVectorizer()\n",
        "#             count_matrix = cv.fit_transform(common_books['combined_features'])\n",
        "#             cosine_sim = cosine_similarity(count_matrix)\n",
        "#             index = common_books[common_books['Book-Title'] == book_title]['index'].values[0]\n",
        "#             sim_books = list(enumerate(cosine_sim[index]))\n",
        "#             sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
        "#                                       reverse=True)[1:6]\n",
        "            \n",
        "#             books = []\n",
        "#             for i in range(len(sorted_sim_books)):\n",
        "#                 books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['Book-Title'].item())\n",
        "            \n",
        "#             print('Recommendations for \"{}\":'.format(book_title))\n",
        "#             for i, book in enumerate(books):\n",
        "#                 print(i+1, book)\n",
        "                \n",
        "#             print(\"\\nReasons:\")\n",
        "#             for i, book in enumerate(books):\n",
        "#                 index = common_books[common_books['Book-Title'] == book]['index'].values[0]\n",
        "#                 if basis is not None:\n",
        "#                     common = common_books[common_books[basis] == common_books[basis].iloc[index]]\n",
        "#                     print(\"{}. Similar to '{}' based on {}\".format(i+1, book_title, basis))\n",
        "#                     print(\"   Recommended because of the following books with same {}: {}\".format(basis, list(common['Book-Title'].unique())))\n",
        "#                 else:\n",
        "#                     author = common_books['Book-Author'].iloc[index]\n",
        "#                     publisher = common_books['Publisher'].iloc[index]\n",
        "#                     print(\"{}. Similar to '{}' based on author and publisher\".format(i+1, book_title))\n",
        "#                     print(\"   Recommended because it has the same author '{}' and publisher '{}' as '{}'\".format(author, publisher, book_title))\n",
        "            \n",
        "#         return\n",
        "    \n",
        "#     else:\n",
        "        \n",
        "#         print('Can\\'t find book in dataset, please check spelling')\n"
      ],
      "metadata": {
        "id": "NQao4zSF9Tdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# content_based_recommender(\"The Testament\", basis=None)\n"
      ],
      "metadata": {
        "id": "ctvkEvc99YgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def content_based_recommender_table(book_title):\n",
        "    \n",
        "#     book_title = str(book_title)\n",
        "#     if book_title in Content_based_df['Book-Title'].values:\n",
        "#         rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts())\n",
        "#         rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index\n",
        "#         common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]\n",
        "        \n",
        "#         if book_title in rare_books:\n",
        "            \n",
        "#             random = pd.Series(common_books['Book-Title'].unique()).sample(2).values\n",
        "#             print('There are no recommendations for this book')\n",
        "#             print('Try: \\n')\n",
        "#             print('{}'.format(random[0]),'\\n')\n",
        "#             print('{}'.format(random[1]),'\\n')\n",
        "        \n",
        "#         else:\n",
        "            \n",
        "#             common_books = common_books.drop_duplicates(subset=['Book-Title'])\n",
        "#             common_books.reset_index(inplace= True)\n",
        "#             common_books['index'] = [i for i in range(common_books.shape[0])]\n",
        "            \n",
        "#             target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "#             common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
        "                \n",
        "#             cv = CountVectorizer()\n",
        "#             count_matrix = cv.fit_transform(common_books['combined_features'])\n",
        "#             cosine_sim = cosine_similarity(count_matrix)\n",
        "#             index = common_books[common_books['Book-Title'] == book_title]['index'].values[0]\n",
        "#             sim_books = list(enumerate(cosine_sim[index]))\n",
        "#             sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
        "#                                       reverse=True)[1:6]\n",
        "            \n",
        "#             books = []\n",
        "#             for i in range(len(sorted_sim_books)):\n",
        "#                 books.append(common_books[common_books['index'] == sorted_sim_books[i][0]])\n",
        "            \n",
        "#             output_table = pd.concat(books)\n",
        "#             output_table.drop(columns=['index', 'combined_features'], inplace=True)\n",
        "#             output_table.index = [i+1 for i in range(output_table.shape[0])]\n",
        "            \n",
        "#             print('Recommendations for \"{}\" based on Author and Publisher:'.format(book_title))\n",
        "#             print(output_table[['Book-Title', 'Book-Author', 'Publisher']])\n",
        "            \n",
        "#         return\n",
        "    \n",
        "#     else:\n",
        "        \n",
        "#         print('Can\\'t find book in dataset, please check spelling')\n"
      ],
      "metadata": {
        "id": "uhTp2eHvAYLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# content_based_recommender_table('The Testament')"
      ],
      "metadata": {
        "id": "8XfoLa1kAgvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBuWVkWRXuyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Content_based_df['Book-Title'] = Content_based_df['Book-Title'].astype(str)"
      ],
      "metadata": {
        "id": "xqG3CFOjby4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts())\n",
        "rating_counts"
      ],
      "metadata": {
        "id": "CdkvWHd_eD4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index\n",
        "rare_books"
      ],
      "metadata": {
        "id": "1ePgWuGzeW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]\n",
        "common_books"
      ],
      "metadata": {
        "id": "aCG7_KuyelJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random = pd.Series(common_books['Book-Title'].unique()).sample(2).values\n",
        "random"
      ],
      "metadata": {
        "id": "rMiJo6dve7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books = common_books.drop_duplicates(subset=['Book-Title'])\n",
        "common_books"
      ],
      "metadata": {
        "id": "sl7UCFL-f_HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books.reset_index(inplace= True)\n"
      ],
      "metadata": {
        "id": "JREHwlzmg4y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books['index'] = [i for i in range(common_books.shape[0])]"
      ],
      "metadata": {
        "id": "wsgiU670gJEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]"
      ],
      "metadata": {
        "id": "WNxutJvMf7rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books"
      ],
      "metadata": {
        "id": "jvzGQqdFhEcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(common_books['combined_features'])\n",
        "count_matrix"
      ],
      "metadata": {
        "id": "uY8Sh5ERhFnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "cosine_sim"
      ],
      "metadata": {
        "id": "6xjoH8jlhFNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D497mt1yiPfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_books = list(enumerate(cosine_sim[index]))\n",
        "sim_books"
      ],
      "metadata": {
        "id": "D6D--PCqjTZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
        "                                      reverse=True)[1:6]\n",
        "sorted_sim_books"
      ],
      "metadata": {
        "id": "BZGHQF__jZsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = []\n",
        "for i in range(len(sorted_sim_books)):\n",
        "    books.append(common_books[common_books['index'] == sorted_sim_books[i][0]])\n",
        "            \n",
        "output_table = pd.concat(books)\n",
        "output_table.drop(columns=['index', 'combined_features'], inplace=True)\n",
        "output_table.index = [i+1 for i in range(output_table.shape[0])]\n",
        "            \n",
        "print('Recommendations for \"{}\" based on Author and Publisher:'.format(book_title))\n",
        "print(output_table[['Book-Title', 'Book-Author', 'Publisher']])"
      ],
      "metadata": {
        "id": "_bQNKweQi2ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns B and C\n",
        "Content_based_df1 = Content_based_df.drop(['Age', 'Country','ISBN','Avg_Rating'], axis=1)\n",
        "Content_based_df1.head()"
      ],
      "metadata": {
        "id": "oXV_tmy1hjx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_strength = {1: 0.5, 2: 1.0, 3: 1.5, 4: 2.0, 5: 2.5, 6: 3.0, 7: 3.5, 8: 4.0,  9: 4.5, 10: 5.0}\n",
        "Content_based_df1['eventStrength'] = Content_based_df1['Book-Rating'].map(rating_strength)"
      ],
      "metadata": {
        "id": "2mGiaOq1OxAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_interactions = Content_based_df1.groupby(['User-ID', 'Book-Title','Book-Author','Year-Of-Publication']).size().groupby('User-ID').size()\n",
        "print('# of users: %d' % len(users_interactions))\n",
        "\n",
        "users_with_5 = users_interactions[users_interactions >= 5].reset_index()[['User-ID']]\n",
        "print('# of users with at least 5 interactions: %d' % len(users_with_5))"
      ],
      "metadata": {
        "id": "1tYXzr4CPwuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_with_5.head()"
      ],
      "metadata": {
        "id": "xKQz9yXCi644"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('# of interactions: %d' % len(Content_based_df))\n",
        "interactions_from_selected_users_df = Content_based_df1.merge(users_with_5, \n",
        "               how='right',\n",
        "               left_on='User-ID',\n",
        "               right_on='User-ID')\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))\n"
      ],
      "metadata": {
        "id": "hwgw4KwBQhEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_from_selected_users_df.head()"
      ],
      "metadata": {
        "id": "Uj_xP6SijYMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "\n",
        "interactions_full_df = interactions_from_selected_users_df \\\n",
        "                    .groupby(['User-ID', 'Book-Title','Book-Author','Year-Of-Publication'])['Book-Rating'].sum() \\\n",
        "                    .apply(smooth_user_preference).reset_index()\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
        "interactions_full_df.head(10)"
      ],
      "metadata": {
        "id": "nYJ6qNwiQ7-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_train_df, Final_test_df = train_test_split(interactions_full_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(Final_train_df)}\")\n",
        "print(f\"Number of samples in test set: {len(Final_test_df)}\") "
      ],
      "metadata": {
        "id": "WqNuVQ_MNRZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_train_df.head() "
      ],
      "metadata": {
        "id": "OpfDEMidgc0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_test_df.head()"
      ],
      "metadata": {
        "id": "I6lyCQlhj8pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "# stopwords_list = stopwords.words('english') \n",
        "\n",
        "# Combine the text columns into a single column\n",
        "#Final_df['text'] = Final_df['Book-Title'] + ' ' + Final_df['Book-Author'] + ' ' + Final_df['Publisher']\n",
        "\n",
        "# #Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "# vectorizer = TfidfVectorizer(analyzer='word',\n",
        "#                      ngram_range=(1, 2),\n",
        "#                      min_df=0.003,\n",
        "#                      max_df=0.5,\n",
        "#                      max_features=10000,\n",
        "#                      stop_words=stopwords_list)\n",
        "\n",
        "# item_ids = Final_df['User-ID'].tolist()\n",
        "# tfidf_matrix = vectorizer.fit_transform(Final_df['Book-Title'] + \"\" + Final_df['Book-Author'] + \"\" + Final_df['Publisher'])\n",
        "# tfidf_feature_names = list(vectorizer.vocabulary_.keys())\n",
        "# tfidf_matrix\n",
        "\n",
        "\n",
        "# # Print the shape of the TF-IDF matrix\n",
        "# print(tfidf_matrix.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "toMAsWyCSxnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TfidfVectorizer for the text-based features\n",
        "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0.003, max_df=0.5,max_features=10000,stop_words='english')\n",
        "tfidf"
      ],
      "metadata": {
        "id": "QlGOQnP9Rtkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_train_matrix = tfidf.fit_transform(Final_train_df['Book-Title'] + \"\" + Final_train_df['Book-Author'])\n",
        "tfidf_feature_names = list(tfidf.vocabulary_.keys())\n",
        "tfidf_train_matrix\n",
        "# Print the shape of the TF-IDF matrix\n",
        "print(tfidf_train_matrix.shape)"
      ],
      "metadata": {
        "id": "hkccKfrNf6De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_test_matrix = tfidf.fit_transform(Final_test_df['Book-Title'] + \"\" + Final_test_df['Book-Author'])\n",
        "tfidf_feature_names = list(tfidf.vocabulary_.keys())\n",
        "tfidf_test_matrix\n",
        "# Print the shape of the TF-IDF matrix\n",
        "print(tfidf_test_matrix.shape)"
      ],
      "metadata": {
        "id": "OLuyOZpNkmzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_test_matrix"
      ],
      "metadata": {
        "id": "GVWz-YohlwU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Yq_tGmaFmNDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the cosine similarity matrix\n",
        "cosine_sim_train = cosine_similarity(tfidf_train_matrix, tfidf_train_matrix)"
      ],
      "metadata": {
        "id": "8X2qAJ0OewfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove irrelevant columns\n",
        "Final_content_based = Content_based_df.drop(['Age','Country', 'ISBN', 'Avg_Rating'], axis=1)"
      ],
      "metadata": {
        "id": "o96hgR8MHops"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_content_based.info()"
      ],
      "metadata": {
        "id": "BFStpEkDMW3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# calculate the TF-IDF matrix for book titles\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(Final_content_based['Book-Title'])\n",
        "\n",
        "# calculate the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# define a function to get book recommendations\n",
        "def get_recommendations(title):\n",
        "    # get the index of the book that matches the title\n",
        "    idx = Final_content_based.loc[Final_content_based['Book-Title'] == title].index[0]\n",
        "\n",
        "    # get the pairwise similarity scores for all books\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # sort the books based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # get the top 10 most similar books\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # get the book indices\n",
        "    book_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # return the top 10 most similar books\n",
        "    return Final_content_based[['Book-Title', 'Book-Author']].iloc[book_indices]\n"
      ],
      "metadata": {
        "id": "WZmYqfiRGGZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates based on Book-Title, Book-Author, and Year-Of-Publication columns\n",
        "duplicates = Final_content_based.duplicated(subset=['Book-Title', 'Book-Author', 'Year-Of-Publication'], keep=False)\n",
        "\n",
        "# print the duplicate rows\n",
        "print(Final_content_based[duplicates])\n"
      ],
      "metadata": {
        "id": "PuupHvJ7Ndmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(Final_content_based, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HCPnr7nUMwlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "qkwxo-wJXT8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "Dh4WpKW2XYbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "tzFUiAGpXkcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix"
      ],
      "metadata": {
        "id": "2qnLuKNbb73a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_features_train = tfidf.fit_transform(train_df['Book-Title'] + ' ' + train_df['Book-Author'] + ' ' + train_df['Publisher'])\n",
        "year_features_train = csr_matrix(pd.get_dummies(train_df['Year-Of-Publication'], prefix='year',sparse=True))\n",
        "rating_features_train = csr_matrix(pd.get_dummies(train_df['Book-Rating'], prefix='rating',sparse=True))"
      ],
      "metadata": {
        "id": "5Q_PmEDBhvm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random sparse matrix\n",
        "X = csr_matrix(pd.get_dummies(train_df['Year-Of-Publication'], prefix='year',sparse=True))\n",
        "# convert to a dense matrix\n",
        "X_dense = X.toarray()\n",
        "\n",
        "# print the dense matrix\n",
        "print(X_dense)"
      ],
      "metadata": {
        "id": "Aehbe-GjPytz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year_features_train"
      ],
      "metadata": {
        "id": "hj5Fp29OQCmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_features_train"
      ],
      "metadata": {
        "id": "5KSWev2rQFZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_train = hstack([book_features_train, year_features_train, rating_features_train], format='csr')"
      ],
      "metadata": {
        "id": "fBquS5w_iuGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\n",
        "users_items_pivot_matrix_df = matrix_train.pivot(index='personId', \n",
        "                                                          columns='contentId', \n",
        "                                                          values='eventStrength').fillna(0)\n",
        "\n",
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "b7Nlf9RW-gUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_train"
      ],
      "metadata": {
        "id": "qHTyRIdfQH4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler"
      ],
      "metadata": {
        "id": "V18NyZtlkUUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data to a standard range\n",
        "scaler = MaxAbsScaler()\n",
        "train_tfidf_norm = scaler.fit_transform(matrix_train)"
      ],
      "metadata": {
        "id": "pmR7FQepkQlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a matrix of tf-idf features for the testing set\n",
        "book_features_test = tfidf.transform(test_df['Book-Title'] + ' ' + test_df['Book-Author'] + ' ' + test_df['Publisher'])\n",
        "year_features_test = csr_matrix(pd.get_dummies(test_df['Year-Of-Publication'], prefix='year'))\n",
        "rating_features_test = csr_matrix(pd.get_dummies(test_df['Book-Rating'], prefix='rating'))"
      ],
      "metadata": {
        "id": "vyJdykfmlFtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_features_test"
      ],
      "metadata": {
        "id": "RXweH00iRYAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year_features_test"
      ],
      "metadata": {
        "id": "uybBgQPmRb_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_features_test"
      ],
      "metadata": {
        "id": "LrQbHUO8RfrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_test = hstack([book_features_test, year_features_test, rating_features_test], format='csr')"
      ],
      "metadata": {
        "id": "geljS7czlKAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tfidf_norm = scaler.fit_transform(matrix_test)"
      ],
      "metadata": {
        "id": "TzlnHsP0lRl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Hpz7ZObpm9K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim_train = cosine_similarity(matrix_train)\n"
      ],
      "metadata": {
        "id": "CrNukkFVluVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the training data\n",
        "train_tfidf = tfidf.fit_transform(train_df['Book-Title'] + ' ' + train_df['Book-Author'])\n",
        "\n",
        "# Scale the data to a standard range\n",
        "scaler = MaxAbsScaler()\n",
        "train_tfidf_norm = scaler.fit_transform(train_tfidf)\n",
        "\n",
        "# Transform the testing data using the same vectorizer and scaler\n",
        "test_tfidf = tfidf.transform(test_df['Book-Title'] + ' ' + test_df['Book-Author'])\n",
        "test_tfidf_norm = scaler.transform(test_tfidf)"
      ],
      "metadata": {
        "id": "ynh6sIrOXBdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_profile(user_id, df, tfidf):\n",
        "    # get all the books the user has rated\n",
        "    user_ratings = df.loc[df['User-ID'] == user_id]\n",
        "\n",
        "    # calculate the weighted average of the book feature vectors based on the user's ratings\n",
        "    book_features = tfidf.transform(user_ratings['Book-Title'] + ' ' + user_ratings['Book-Author'] + ' ' + user_ratings['Publisher'])\n",
        "    user_ratings_normalized = user_ratings['Book-Rating'] - user_ratings['Book-Rating'].mean()\n",
        "    user_ratings_normalized = user_ratings_normalized / user_ratings_normalized.abs().sum()\n",
        "    user_profile = (user_ratings_normalized.values.reshape(1, -1) @ book_features).squeeze()\n",
        "\n",
        "    # normalize the user profile feature vector\n",
        "    user_profile_norm = user_profile / np.linalg.norm(user_profile)\n",
        "\n",
        "    return user_profile_norm\n"
      ],
      "metadata": {
        "id": "HBmkACoxfRwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a matrix of tf-idf features for the training set\n",
        "book_features_train = tfidf.fit_transform(train_df['Book-Title'] + ' ' + train_df['Book-Author'] + ' ' + train_df['Publisher'])\n",
        "user_features_train = pd.get_dummies(train_df['User-ID'], prefix='user', sparse=True)\n",
        "year_features_train = pd.get_dummies(train_df['Year-Of-Publication'], prefix='year', sparse=True)\n",
        "rating_features_train = pd.get_dummies(train_df['Book-Rating'], prefix='rating', sparse=True)\n"
      ],
      "metadata": {
        "id": "6dWYLK5EcDCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a matrix of tf-idf features for the training set\n",
        "book_features_train = tfidf.fit_transform(train_df['Book-Title'] + ' ' + train_df['Book-Author'] + ' ' + train_df['Publisher'])\n",
        "user_features_train = pd.get_dummies(train_df['User-ID'], prefix='user')\n",
        "year_features_train = pd.get_dummies(train_df['Year-Of-Publication'], prefix='year')\n",
        "rating_features_train = pd.get_dummies(train_df['Book-Rating'], prefix='rating')\n",
        "matrix_train = pd.concat([book_features_train, user_features_train, year_features_train, rating_features_train], axis=1)"
      ],
      "metadata": {
        "id": "Wa4BEkOkJGZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a matrix of tf-idf features for the testing set\n",
        "book_features_test = tfidf.transform(test_df['Book-Title'] + ' ' + test_df['Book-Author'] + ' ' + test_df['Publisher'])\n",
        "user_features_test = pd.get_dummies(test_df['User-ID'], prefix='user')\n",
        "year_features_test = pd.get_dummies(test_df['Year-Of-Publication'], prefix='year')\n",
        "rating_features_test = pd.get_dummies(test_df['Book-Rating'], prefix='rating')\n",
        "matrix_test = pd.concat([book_features_test, user_features_test, year_features_test, rating_features_test], axis=1)\n"
      ],
      "metadata": {
        "id": "gxa10R7vWtjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YN3xz7kyZfV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Convert categorical variables to numerical form\n",
        "Content_df['Country'] = pd.factorize(Content_df['Country'])[0]\n",
        "Content_df['Book-Title'] = pd.factorize(Content_df['Book-Title'])[0]\n",
        "Content_df['Book-Author'] = pd.factorize(Content_df['Book-Author'])[0]\"\"\""
      ],
      "metadata": {
        "id": "pR8N4e4BI1_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert any non-string values in the Book-Title and Book-Author columns to empty strings\n",
        "Content_df['Book-Title'] = Content_df['Book-Title'].apply(lambda x: str(x) if isinstance(x, (int, float)) else x)\n",
        "Content_df['Book-Author'] = Content_df['Book-Author'].apply(lambda x: str(x) if isinstance(x, (int, float)) else x)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Extract features from the Book-Title column\n",
        "title_features = vectorizer.fit_transform(Content_df['Book-Title'])\n",
        "\n",
        "# Extract features from the Book-Author column\n",
        "author_features = vectorizer.fit_transform(Content_df['Book-Author'])\"\"\""
      ],
      "metadata": {
        "id": "21rEIvXyJgcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Calculate the cosine similarity between the user's preferences and the book titles\n",
        "title_similarity = cosine_similarity(title_features, title_features)\n",
        "# Calculate the cosine similarity between the user's preferences and the book authors\n",
        "author_similarity = cosine_similarity(author_features, author_features)"
      ],
      "metadata": {
        "id": "OiaQnRvlL_hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(title_similarity)"
      ],
      "metadata": {
        "id": "IeMXHDtUMfsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(author_similarity)"
      ],
      "metadata": {
        "id": "ew7kGKwvMlfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def recommend_books(user_preferences, num_recommendations):\n",
        "    # Convert the user preferences to a DataFrame\n",
        "    user_df = pd.DataFrame(user_preferences, columns=['Book-Title', 'Book-Author'])\n",
        "    # Calculate the weighted average of the similarity scores\n",
        "    similarity_scores = (title_similarity * 0.5) + (author_similarity * 0.5)\n",
        "\n",
        "    # Get the indices of the top recommendations\n",
        "    top_indices = np.argsort(-similarity_scores)[:num_recommendations]\n",
        "\n",
        "    # Get the top recommendations\n",
        "    top_recommendations = Content_df.loc[top_indices]\n",
        "\n",
        "    return top_recommendations\"\"\""
      ],
      "metadata": {
        "id": "cPbQxsTxMduA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_preferences = [('The Catcher in the Rye', 'J.D. Salinger'), ('To Kill a Mockingbird', 'Harper Lee')]\n",
        "#recommendations = recommend_books(user_preferences, 10)"
      ],
      "metadata": {
        "id": "-v78UmcDQUtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Content_df.head()"
      ],
      "metadata": {
        "id": "0NYLizBUNL9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}