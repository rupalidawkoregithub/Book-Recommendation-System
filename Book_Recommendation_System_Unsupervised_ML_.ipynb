{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rupalidawkoregithub/Book-Recommendation-System/blob/main/Book_Recommendation_System_Unsupervised_ML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Book Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual Notebook\n",
        "##### **Team Member 1 -** Rupali Dawkore\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**Problem Statement:**\n",
        "\n",
        "The rise of internet services such as Youtube, Amazon, and Netflix has resulted in an increase in the popularity of recommender systems. Recommender systems are algorithms designed to suggest relevant items to users based on their preferences. They have become essential in various industries, including e-commerce, online advertising, and streaming services. In this project, we will develop a book recommendation system for users based on the Book-Crossing dataset. We will use unsupervised machine learning techniques such as exploratory data analysis, content-based filtering.\n",
        "##**Book-Crossing Dataset:**\n",
        "\n",
        "The Book-Crossing dataset contains three files: Users, Books, and Ratings. The Users file contains demographic information about users, including their location and age. The Books file provides information about books, including their ISBN, author, title, and publication year. The Ratings file contains information about the ratings given by users to books. Ratings range from 1 to 10, with higher values indicating higher appreciation. Some ratings are implicit and expressed by 0.5.\n",
        "\n",
        "##**Exploratory Data Analysis (EDA):**\n",
        "\n",
        "Before developing our recommendation models, we will perform EDA to understand the characteristics of the dataset. EDA helps us to identify missing values, outliers, and correlations between variables. It also provides insights into the distribution of data, which can inform our modeling decisions.\n",
        "\n",
        "##**Content-Based Filtering:**\n",
        "\n",
        "Our ML model is based on content-based filtering.The ML model 1 is based on content-based filtering. It recommends books to users based on their past preferences. The model first cleans and preprocesses the dataset by removing unwanted columns and duplicating rows. It then vectorizes the text data by tokenizing and converting them into numerical data using TfidfVectorizer. After vectorizing the text data, it creates a cosine similarity matrix that measures the similarity between each book based on their textual features. Finally, the model recommends top-n similar books to a given book based on their cosine similarity score.\n",
        "\n",
        "Overall, ML models are designed to recommend books to users based on their preferences. Model 1 is based on the textual features of the books.\n",
        "\n",
        "##**Conclusion:**\n",
        "\n",
        "The development of recommender systems has become increasingly important in various industries, including e-commerce, online advertising, and streaming services. the book recommendation system developed using the Book-Crossing dataset has ML models based on unsupervised learning techniques: content-based filtering. These models use different approaches to recommend books to users based on their preferences. The content-based filtering approach recommends books based on the textual features of the books."
      ],
      "metadata": {
        "id": "MOjgHgjS1YNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rupali Dawkore : https://github.com/rupalidawkoregithub/Book-Recommendation-System"
      ],
      "metadata": {
        "id": "HWZzfJoZx3SU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors.\n",
        "\n",
        "The main objective is to create a book recommendation system for users.\n",
        "\n",
        "Content\n",
        "The Book-Crossing dataset comprises 3 files.\n",
        "\n",
        "● Users\n",
        "\n",
        "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL values.\n",
        "\n",
        "● Books\n",
        "\n",
        "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in the case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavors (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon website.\n",
        "\n",
        "● Ratings\n",
        "\n",
        "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing All Neccessary Libraries\n",
        "# importing regular expression library\n",
        "import re\n",
        "# importing pickle library for object serialization\n",
        "import pickle\n",
        "# importing operator library for efficient operators\n",
        "import operator\n",
        "# importing pandas library for data manipulation\n",
        "import pandas as pd\n",
        "# Importing NumPy library for numerical computations and array manipulations\n",
        "import numpy as np \n",
        "# importing matplotlib library for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "# importing seaborn library for statistical graphics\n",
        "import seaborn as sns\n",
        "# importing missingo library which helps us to visualize the missing values\n",
        "import missingno as msno\n",
        "# This is to supress the warning messages (if any) generated in our code\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "# importing scipy library for scientific computing and technical computing\n",
        "import scipy\n",
        "# importing math library for mathematical operations\n",
        "import math\n",
        "# importing random library for generating random numbers\n",
        "import random\n",
        "# importing sklearn library for machine learning algorithms and tools\n",
        "import sklearn\n",
        "# importing stopwords from NLTK corpus to remove stopwords from text data\n",
        "from nltk.corpus import stopwords\n",
        "# importing train_test_split function from sklearn library for splitting dataset\n",
        "from sklearn.model_selection import train_test_split \n",
        "# importing CountVectorizer from sklearn library for text preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# importing normalize function from sklearn library for normalizing the data\n",
        "from sklearn.preprocessing import normalize\n",
        "# importing svds function from scipy.sparse.linalg library for singular value decomposition\n",
        "from scipy.sparse.linalg import svds\n",
        "# Importing the Counter class from the collections module\n",
        "from collections import Counter\n",
        "# Importing the compressed sparse row matrix class from scipy.sparse module    \n",
        "from scipy.sparse import csr_matrix \n",
        "# Importing the is_numeric_dtype function from the pandas.api.types module  \n",
        "from pandas.api.types import is_numeric_dtype\n",
        "# Importing the NearestNeighbors class from the sklearn.neighbors module\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "# Importing the DictVectorizer class from the sklearn.feature_extraction module   \n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "# Importing the cosine_similarity function from the sklearn.metrics.pairwise module   \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Importing the TfidfVectorizer class from the sklearn.feature_extraction.text module   \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Importing the mstats module from the scipy.stats module   \n",
        "from scipy.stats import mstats\n",
        "# Importing the trim_mean function from the scipy.stats module   \n",
        "from scipy.stats import trim_mean \n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive for access the dataset of Book Recommendation System\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading datasets of Book Recommendation Systems \n",
        "books_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Books.csv\")     # Read books csv file\n",
        "users_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Users.csv\")     # Read users csv file\n",
        "ratings_df = pd.read_csv(\"/content/drive/MyDrive/Book Recommendation /Ratings.csv\") # Read users csv file"
      ],
      "metadata": {
        "id": "s8kUSQz_Krhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape of each dataframe \n",
        "print(\"Books Data:\", books_df.shape)        # Checked shape of books dataframe\n",
        "print(\"Books-ratings :\", ratings_df.shape)  # Checked shape of ratings dataframe\n",
        "print(\"Users Data:\", users_df.shape)        # Checked shape of users dataframe\n"
      ],
      "metadata": {
        "id": "u7ZL1fwoqrXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Books Dataset**"
      ],
      "metadata": {
        "id": "jyoxpEv81PkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "books_df.info() "
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code sets the maximum column width to be unlimited.\n",
        "pd.set_option('display.max_colwidth', -1) "
      ],
      "metadata": {
        "id": "LieEliMHMeyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "ZF-yyObuFe4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows and columns\n",
        "rows, columns = books_df.shape "
      ],
      "metadata": {
        "id": "vkRi4VGHqReZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns\n",
        "print(\"Number of rows: \", rows)\n",
        "print(\"Number of columns: \", columns) "
      ],
      "metadata": {
        "id": "7JMoXvXxy3u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking all columns from books dataframe and looking forward the first 5 rows\n",
        "print(\"Columns: \", list(books_df.columns))\n",
        "books_df.head() "
      ],
      "metadata": {
        "id": "RVq2QTleLX8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dataset Information"
      ],
      "metadata": {
        "id": "nDEbkxCCF7Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking book dataset information\n",
        "books_df.info() "
      ],
      "metadata": {
        "id": "IbGFrmNFKL65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Duplicate Values"
      ],
      "metadata": {
        "id": "cvQaDZDKGGT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in books dataset: {books_df.duplicated().sum()}\") "
      ],
      "metadata": {
        "id": "y0mPAHsMGHiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicate Values in Books Dataframe."
      ],
      "metadata": {
        "id": "0jEdfnOur6sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Dropping Columns"
      ],
      "metadata": {
        "id": "MIFBxB30tG5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Unnecessary URL columns\n",
        "books_df.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
        "books_df.head() "
      ],
      "metadata": {
        "id": "cAy-w3C8Dh83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Missing Values/Null Values"
      ],
      "metadata": {
        "id": "wit8Xli6FqDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making function to check missing or null values of dataframes\n",
        "def missing_values(df): \n",
        "    mis_val=df.isnull().sum()\n",
        "    mis_val_percent=round(df.isnull().mean().mul(100),2)\n",
        "    mz_table=pd.concat([mis_val,mis_val_percent],axis=1)\n",
        "    mz_table=mz_table.rename(\n",
        "    columns={df.index.name:'col_name',0:'Missing Values',1:'% of Total Values'})\n",
        "    mz_table['Data_type']=df.dtypes\n",
        "    mz_table=mz_table.sort_values('% of Total Values',ascending=False)\n",
        "    return mz_table.reset_index()"
      ],
      "metadata": {
        "id": "_KsxjKfCLndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values for books dataframe\n",
        "missing_values(books_df) "
      ],
      "metadata": {
        "id": "k80Br5v8HGn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(books_df,figsize=(10,5), color=\"tab:cyan\") "
      ],
      "metadata": {
        "id": "_fA1hx7VeUMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have missing value in Book-Author & Publisher.   "
      ],
      "metadata": {
        "id": "AKPqz5Gzt7Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Index of null values \n",
        "books_df.loc[books_df['Book-Author'].isnull(),:] "
      ],
      "metadata": {
        "id": "jKqs_iqhLvvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing value of book author with other\n",
        "books_df.at[187689 ,'Book-Author'] = 'Others' "
      ],
      "metadata": {
        "id": "36DsZimLC_pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Index of null values \n",
        "books_df.loc[books_df['Publisher'].isnull(),:] "
      ],
      "metadata": {
        "id": "OOwFtwJVL1pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing value of publisher with other\n",
        "books_df.at[128890 ,'Publisher'] = 'Others'\n",
        "books_df.at[129037 ,'Publisher'] = 'Others' "
      ],
      "metadata": {
        "id": "sRUh8CVBDKMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "eXoI3BkWt7pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "books_df.columns "
      ],
      "metadata": {
        "id": "W7m_uzKEt7pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe \n",
        "books_df.describe()"
      ],
      "metadata": {
        "id": "nWDJrhqFt7pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variables Description "
      ],
      "metadata": {
        "id": "wv-Kj_MSt7pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1.  ISBN :**  This column represents the unique International Standard Book Number for each book in the dataframe. Each book has a distinct ISBN.\n",
        "\n",
        " **2.  Book-Title   :**  This column represents the title of each book. It is a categorical variable that can take on one of several possible values, such as \"Classical Mythology\", \"Clara Callan\"\n",
        "\n",
        " **3.  Book-Author       :**  This column represents the author of each book. It is a categorical variable.\n",
        "\n",
        " **4.Year-Of-Publication :** This column represents the year in which each book was published. It is a discrete numerical variable that can take on integer values greater than or equal to 0, such as 2002, 2001, 1991, 1999, and so on.\n",
        "\n",
        " **5.Publisher :**  This column represents the publisher of each book. It is a categorical variable that can take on one of several possible values.\n",
        "\n",
        " **6.Image-URL-S :**  This column represents the URL for a small image of the book cover. It is a categorical variable that contains the URL for a thumbnail-sized image of the book cover.\n",
        "\n",
        " **7.Image-URL-M:**  This column represents the URL for a medium image of the book cover. It is a categorical variable that contains the URL for a medium-sized image of the book cover.\n",
        "\n",
        " **8.Image-URL-L:**  This column represents the URL for a large image of the book cover. It is a categorical variable that contains the URL for a full-sized image of the book cover."
      ],
      "metadata": {
        "id": "c3TXgWYSBuvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "Qx-I1JoqvPKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking for columns in Books dataset\n",
        "books_df.columns "
      ],
      "metadata": {
        "id": "CpU3SkBrvPKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for printing the Unique Values of Each column in dataframe\n",
        "def get_all_unique_values(df):\n",
        "    for col in df.columns:\n",
        "        print(f\"Unique values in column '{col}':\")\n",
        "        print(df[col].unique()) \n",
        "        print()"
      ],
      "metadata": {
        "id": "qHXJfZbGgWsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(books_df) "
      ],
      "metadata": {
        "id": "P4yfO0xWgr71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique values for column Year-of-publication\n",
        "books_df['Year-Of-Publication'].unique() "
      ],
      "metadata": {
        "id": "K4zTmBpaMI6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the values of DK Publishing Inc\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'DK Publishing Inc',:] "
      ],
      "metadata": {
        "id": "gpKLjJVNzcOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the values of Gallimard\n",
        "books_df.loc[books_df['Year-Of-Publication'] == 'Gallimard',:] "
      ],
      "metadata": {
        "id": "2ojtr41OzllM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As it can be seen from above that there are some incorrect entries in Year-Of-Publication field. It looks like Publisher names 'DK Publishing Inc' and 'Gallimard' have been incorrectly loaded as Year-Of-Publication in dataset due to some errors in csv file.**"
      ],
      "metadata": {
        "id": "Dk_18Opez1KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From above, it is seen that bookAuthor is incorrectly loaded with Year-Of-Publication, hence making required corrections\n",
        "#ISBN '078946697X'\n",
        "books_df.at[209538 ,'Publisher'] = 'DK Publishing Inc'\n",
        "books_df.at[209538 ,'Year-Of-Publication'] = 2000\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Author'] = 'Michael Teitelbaum' "
      ],
      "metadata": {
        "id": "Z0cHIOlp4aKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ISBN '0789466953'\n",
        "books_df.at[221678 ,'Publisher'] = 'DK Publishing Inc'\n",
        "books_df.at[221678 ,'Year-Of-Publication'] = 2000\n",
        "books_df.at[209538 ,'Book-Title'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
        "books_df.at[209538 ,'Book-Author'] = 'James Buckley' "
      ],
      "metadata": {
        "id": "OhCVxHwh5CnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ISBN '2070426769'\n",
        "books_df.at[220731 ,'Publisher'] = 'Gallimard'\n",
        "books_df.at[220731 ,'Year-Of-Publication'] = 2003\n",
        "books_df.at[209538 ,'Book-Title'] = 'Peuple du ciel - Suivi de Les bergers '\n",
        "books_df.at[209538 ,'Book-Author'] = 'Jean-Marie Gustave Le ClÃ?Â©zio'"
      ],
      "metadata": {
        "id": "kBtZnPFOBE1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert \"Fee\" from String to int\n",
        "books_df= books_df.astype({'Year-Of-Publication':'int'})\n",
        "print(books_df.dtypes)"
      ],
      "metadata": {
        "id": "cIbCrlpZd3SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df[\"Year-Of-Publication\"].shape"
      ],
      "metadata": {
        "id": "ASD_1IIQBg0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_df['Year-Of-Publication'].unique() "
      ],
      "metadata": {
        "id": "neypbWfzCPKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_years = sorted(books_df['Year-Of-Publication'].unique())\n",
        "print(sorted_years)"
      ],
      "metadata": {
        "id": "rvAOXsgB5QzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The value 0 for Year-Of_Publication is invalid and as this dataset was published in 2004, We have assumed that the years after 2004 to be invalid and setting invalid years as NaN**"
      ],
      "metadata": {
        "id": "wgjDvbQIPeSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace values greater than 2006 or equal to 0 with NaN\n",
        "# books_df.loc[(books_df['Year-Of-Publication'] > 2004) | (books_df['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "# # Fill NaN values with the median value of the column\n",
        "# books_df['Year-Of-Publication'].fillna(round(books_df['Year-Of-Publication'].median()), inplace=True) "
      ],
      "metadata": {
        "id": "ZC9qzYQiTg86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert invalid values to NaN\n",
        "mask = (books_df['Year-Of-Publication'] > 2004) | (books_df['Year-Of-Publication'] == 0)\n",
        "books_df.loc[mask, 'Year-Of-Publication'] = np.nan\n",
        "# Replace NaN values with median of remaining valid values\n",
        "median_year = books_df['Year-Of-Publication'].median()\n",
        "books_df['Year-Of-Publication'].fillna(median_year, inplace=True) "
      ],
      "metadata": {
        "id": "0DTiWk1XktXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Year-Of-Publication' column in the dataset is of integer type, with values ranging from 0 to 2050. However, as the dataset was created in 2004, it is assumed that all years after 2004 are invalid, allowing for a margin of two years in case the dataset was updated. Any invalid entries in this column, including those with a value of 0, will be converted to NaNs using a boolean mask. Afterward, the remaining valid values in the column will be used to calculate the median year. Finally, all NaN values in the column will be replaced with the calculated median year. This process ensures that the data is clean and usable for analysis."
      ],
      "metadata": {
        "id": "IJ89AS8Zz-Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking unique values for year of publication\n",
        "books_df['Year-Of-Publication'].unique()   "
      ],
      "metadata": {
        "id": "fgksxf4GUxBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Users Dataset**"
      ],
      "metadata": {
        "id": "-u_UUJTXA2As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Users Dataset First Look"
      ],
      "metadata": {
        "id": "6JLEi5NypRj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Dataset First Look\n",
        "users_df.head()     "
      ],
      "metadata": {
        "id": "7lRMjR0tpXs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values for users dataframe\n",
        "missing_values(users_df) "
      ],
      "metadata": {
        "id": "H1KzSCNimjDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "wr9GHBn9IDUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "row,columns=users_df.shape\n",
        "# Print the size of row & column of users dataset \n",
        "print(\"Rows of Users Df\",row) \n",
        "print(\"Columns of Users Df\",columns)    "
      ],
      "metadata": {
        "id": "SNl5B5EgH9io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Information"
      ],
      "metadata": {
        "id": "Ki2iHS9DBQRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking dataset information \n",
        "users_df.info()    "
      ],
      "metadata": {
        "id": "ew_tBumhBFpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This dataset consists of 3 features with 278858 entries with 'Age' column having Null Values."
      ],
      "metadata": {
        "id": "26sbLlu510kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age Column have lots of Null Values"
      ],
      "metadata": {
        "id": "sv4Zf1-T11wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Duplicate Values"
      ],
      "metadata": {
        "id": "aCrWQECDI1cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in users dataset: {users_df.duplicated().sum()}\")   "
      ],
      "metadata": {
        "id": "fWp_v9T9Iq2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicates found."
      ],
      "metadata": {
        "id": "Mlap18Wr2ZnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "uuYKE9l5FTVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "users_df.columns   "
      ],
      "metadata": {
        "id": "F3lgsbH1FTVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "users_df.describe()  "
      ],
      "metadata": {
        "id": "IqPpC47gFTVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "-SSWLLg8FTVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1.  User-ID   :**  This column represents the unique identifier for each user in the dataframe. Each user has a distinct User-ID.\n",
        "\n",
        " **2.  Location  :**  This column represents the location of each user. It is a categorical variable that can take on one of several possible values, such as \"nyc, new york, usa\", \"stockton, california, usa.\"\n",
        "\n",
        " **3.  Age       :** This column represents the age of each user in years. It is a continuous numerical variable that can take any value greater than or equal to 0."
      ],
      "metadata": {
        "id": "fD-qOyx7DYMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "CRFmQcS43XgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking for columns in users dataset\n",
        "users_df.columns  "
      ],
      "metadata": {
        "id": "7XSkuEZSFTVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(users_df) "
      ],
      "metadata": {
        "id": "ANGR1LDfJO6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "cZzvpJJ8I6Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "JewEHUVMIpLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age have around 39% missing values.**"
      ],
      "metadata": {
        "id": "bwFqsjhSL0YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(users_df,figsize=(10,5), color=\"tab:blue\") "
      ],
      "metadata": {
        "id": "oH4IMNNadzVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for all values present in Age column\n",
        "users_df['Age'].unique()   "
      ],
      "metadata": {
        "id": "za08vVjCJSeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of Age column\n",
        "plt.figure(figsize=(8,4)) \n",
        "sns.distplot(users_df['Age']); "
      ],
      "metadata": {
        "id": "La-9uDZC4C86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The feature Age is Rightly skewed. Replacing Null values with Median value"
      ],
      "metadata": {
        "id": "_qnopkHp4k-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon checking the unique values, userID looks correct. However, Age column has a NaN and some very high values. In my view ages below 5 and above 90 do not make much sense, and hence, these are being replaced with NaNs. All the NaNs are then replaced with median value of Age, and its data type is set as int."
      ],
      "metadata": {
        "id": "lAZqDLT25lsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting the unique values of age columns\n",
        "print(sorted(list(users_df['Age'].unique())))   "
      ],
      "metadata": {
        "id": "Nh49v-pJJxZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the values that there are people who are 0 years old and also we have people who are 244 years old which is for sure an error so we will keep the age group only from 5 years old to 100 years old and for the rest we will replace them with median of the age."
      ],
      "metadata": {
        "id": "s7gug46sEA2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing the less than 5 and more than 85 values with mean of the age   \n",
        "# users_df.loc[(users_df['Age'] < 5) | (users_df['Age'] > 100),'Age'] = np.nan\n",
        "# users_df['Age'].fillna((users_df['Age'].median()), inplace=True)    "
      ],
      "metadata": {
        "id": "E4ZOJ_V5PU-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert invalid values to NaN\n",
        "masking= (users_df['Age'] > 100) | (users_df['Age'] < 5)\n",
        "users_df.loc[masking, 'Age'] = np.nan\n",
        "\n",
        "# Replace NaN values with median of remaining valid values\n",
        "median_age = users_df['Age'].median()\n",
        "users_df['Age'].fillna(median_age, inplace=True)"
      ],
      "metadata": {
        "id": "20MvZfiiTv6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking unique values for age columns\n",
        "print(sorted(users_df['Age'].unique())) "
      ],
      "metadata": {
        "id": "G57bWb2mQT0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rehecking the null values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "G4rYQMn86FVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* No Null values are present in Age column."
      ],
      "metadata": {
        "id": "67-7wH-L6TJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "lq9PpQz97A5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "VQB4x5RS7A5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for outliers in age column"
      ],
      "metadata": {
        "id": "LQwMOq2I9tUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking outliers for age\n",
        "sns.boxplot(y='Age', data=users_df)\n",
        "plt.title('Find outlier data in Age column') "
      ],
      "metadata": {
        "id": "tqEdltEC8ecj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There no more outliers in age column."
      ],
      "metadata": {
        "id": "QayAUsL_ETv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking location with unique \n",
        "users_df.Location.unique() "
      ],
      "metadata": {
        "id": "yQxDZlK18utX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking number of unique values for location \n",
        "users_df.Location.nunique() "
      ],
      "metadata": {
        "id": "jd8nC_Nc86q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**57339 unique Value it's really hard to understand,\n",
        "So lets create column Country.**"
      ],
      "metadata": {
        "id": "ulFLrZCt86h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_country(users_df):\n",
        "#     users_df['Country'] = users_df['Location'].str.extract(r',\\s?(\\w+\\s*\\w*)\\\"*$')\n",
        "#     return users_df   "
      ],
      "metadata": {
        "id": "5vW33Mzr7475"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making function to extract country from location in users dataframe\n",
        "import re\n",
        "\n",
        "def extract_country(location):\n",
        "    pattern = r',\\s?(\\w+\\s?\\w*)\\\"*$'\n",
        "    match = re.search(pattern, location)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "users_df['Country'] = users_df['Location'].apply(extract_country)"
      ],
      "metadata": {
        "id": "12zo9Ge1oBc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract_country(users_df) "
      ],
      "metadata": {
        "id": "GSZA_io9WwjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique numbers for country\n",
        "users_df.Country.nunique()  "
      ],
      "metadata": {
        "id": "2OAo5Cf-9UNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop location column\n",
        "users_df.drop('Location',axis=1,inplace=True)  "
      ],
      "metadata": {
        "id": "XxRZZP1x9XfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking head of users df\n",
        "users_df.head(2)  "
      ],
      "metadata": {
        "id": "6Y9F6_we9acb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking missing values of users dataframe\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "KSUbdEc3_K3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_df['Country']=users_df['Country'].astype('str') "
      ],
      "metadata": {
        "id": "tSG704Rp-fmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing country\n",
        "print(users_df['Country'])  "
      ],
      "metadata": {
        "id": "QtuvR2ieYIVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing first 10 country\n",
        "print(users_df['Country'][:10])  "
      ],
      "metadata": {
        "id": "Y8MEG7J4Ywxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Replace some Misspelt Countries \n",
        "users_df['Country'].replace(['','01776','02458','19104','23232','30064','85021','87510','alachua','america','austria',\n",
        "                             'autralia','cananda','geermany','germay','italia','united kindgonm','united sates','united staes',\n",
        "                             'united state','united states','us','urugua','indiai','canada eh','le canada','nan'],\n",
        "                           ['others','usa','usa','usa','usa','usa','usa','usa','usa','usa','australia','australia',\n",
        "                            'canada','germany','germany','italy','united kingdom','usa','usa','usa','usa','usa',\n",
        "                            'uruguay','india','canada','canada','others'],inplace=True)  "
      ],
      "metadata": {
        "id": "yYleBvQPAx8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df['Country'].fillna('other',inplace=True)  "
      ],
      "metadata": {
        "id": "42AT4SyQva8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.head() "
      ],
      "metadata": {
        "id": "FkSk3o9Kvfw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking missing values\n",
        "missing_values(users_df)  "
      ],
      "metadata": {
        "id": "I1T9U5V_BsoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.shape "
      ],
      "metadata": {
        "id": "TKqECxOcYRL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ratings Dataset**"
      ],
      "metadata": {
        "id": "TJa5lrQ7XGsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Ratings Dataset First Look"
      ],
      "metadata": {
        "id": "OmWyatIDaywj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first look for rating dataset\n",
        "ratings_df.head()   "
      ],
      "metadata": {
        "id": "CxvhHYaPazpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.shape "
      ],
      "metadata": {
        "id": "uOosAGfgYvGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "row,col=ratings_df.shape\n",
        "print(\"Row:\",row)\n",
        "print(\"col:\",col)   "
      ],
      "metadata": {
        "id": "5w2Or4LgbJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking all columns from ratings dataframe\n",
        "print(\"Columns: \", list(ratings_df.columns))  "
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "ratings_df.info()  "
      ],
      "metadata": {
        "id": "VXWfsYOQXaah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is No Null Values in the above dataset"
      ],
      "metadata": {
        "id": "nohbjzWPbyLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicated rows in ratings dataset: {ratings_df.duplicated().sum()}\")  "
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is No Duplicates found."
      ],
      "metadata": {
        "id": "RZExT0xycQmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "PFhG6faacRDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "ratings_df.columns  "
      ],
      "metadata": {
        "id": "M0r_4aRAcRDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "ratings_df.describe()  "
      ],
      "metadata": {
        "id": "Iprg8h5bcRDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "36CT4-9LcRDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1.  User-ID           :**   This column represents the unique identifier for each user in the dataframe. Each row represents a rating given by a user for a particular book, and the User-ID column specifies which user gave the rating.\n",
        "\n",
        " **2.  ISBN              :**  This column represents the unique identifier for each book in the dataframe. Each row represents a rating given by a user for a particular book, and the ISBN column specifies which book was rated.\n",
        "\n",
        " **3.  Book-Rating       :**  This column represents the rating given by a user for a particular book. It is a numerical variable that can take on integer values between 0 and 10.\n",
        " "
      ],
      "metadata": {
        "id": "1MlwGCtRFKiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "lhUV7qMudDYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values \n",
        "get_all_unique_values(ratings_df) "
      ],
      "metadata": {
        "id": "k1VngYhrdDYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values of ratings dataframe\n",
        "missing_values(ratings_df)  "
      ],
      "metadata": {
        "id": "R2mYGE54__0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(ratings_df,figsize=(10,5), color=\"tab:green\")  "
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "3i-XShTedDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Wrangling Code"
      ],
      "metadata": {
        "id": "wE2UFjvwdDYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for first row\n",
        "ratings_df.head(1)  "
      ],
      "metadata": {
        "id": "2GMEdilwCXTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ratings dataset should have books only which exist in our books dataset.**"
      ],
      "metadata": {
        "id": "1MoRd4JyChp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only the records of ratings for the books and users whose data is there in the respective users and books csv file\n",
        "#ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]         # Filter ratings to only include ISBN present in books_df \n",
        "#ratings_df = ratings_df[ratings_df['User-ID'].isin(users_df['User-ID'])] # Filter ratings to only include users present in users_df\n"
      ],
      "metadata": {
        "id": "TIUFAy-BTBUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter ratings to only include ISBN present in books_df\n",
        "ratings_df = ratings_df[ratings_df['ISBN'].isin(books_df['ISBN'])]\n",
        "\n",
        "# Filter ratings to only include users present in users_df\n",
        "ratings_df = ratings_df[ratings_df['User-ID'].isin(users_df['User-ID'])]"
      ],
      "metadata": {
        "id": "6WQSGl2XiSU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking dataset information\n",
        "ratings_df.info() "
      ],
      "metadata": {
        "id": "4Px3kQntTe4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape of dataset\n",
        "ratings_df.shape "
      ],
      "metadata": {
        "id": "IC5rOjYNhw4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we have 1048575 shape of ratings df now after manupulation  we have 941112 that means some values are dropped."
      ],
      "metadata": {
        "id": "ZVP7C8b8amcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that no new user was there in ratings dataset."
      ],
      "metadata": {
        "id": "BxPfPHKOEiD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hence segragating implicit and explict ratings datasets\n",
        "ratings_df_explicit = ratings_df[ratings_df['Book-Rating'] != 0]  # In explicit we will take only that is not equal to 0\n",
        "ratings_df_implicit = ratings_df[ratings_df['Book-Rating'] == 0]  # In implicit we will take only that is equal to 0 "
      ],
      "metadata": {
        "id": "WIzwBQlMMiJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After Explicit and Implicit Dataset Shape \n",
        "print('ratings_explicit dataset shape',ratings_df_explicit.shape)\n",
        "print('ratings_implicit dataset',ratings_df_implicit.shape) "
      ],
      "metadata": {
        "id": "QaxFv6E-WfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking first five rows for rating_df_explicit \n",
        "ratings_df_explicit.head()  "
      ],
      "metadata": {
        "id": "dNh7dE5ybi5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute average rating for each book (ISBN)\n",
        "book_ratings = ratings_df_explicit.groupby('ISBN')['Book-Rating'].mean()\n",
        "# Create a new column 'Avg_Rating' and set its values to the corresponding average rating for each book\n",
        "ratings_df_explicit['Avg_Rating'] = ratings_df_explicit['ISBN'].map(book_ratings) "
      ],
      "metadata": {
        "id": "6BCQSMwisa9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating average \n",
        "#ratings_df_explicit['Avg_Rating']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('mean') \n",
        "# Create column Rating sum\n",
        "#ratings_df_explicit['Total_No_Of_Users_Rated']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "C-0EAH2ViidQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking head of explicit rating data\n",
        "ratings_df_explicit.head()   "
      ],
      "metadata": {
        "id": "6prAG_i-jz6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Merging All Dataset.**"
      ],
      "metadata": {
        "id": "A2FFabo_kQdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating final dataframe  \n",
        "Final_df = users_df.copy()                                        # Copy users_df\n",
        "Final_df = pd.merge(Final_df,ratings_df_explicit,on='User-ID')    # Merge ratings_df_explicit on User-ID with final_df  \n",
        "Final_df = pd.merge(Final_df,books_df,on='ISBN')                  # Merge books_df on ISBN with final_df "
      ],
      "metadata": {
        "id": "72toQhqRkLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape of merged dataframe\n",
        "Final_df.shape "
      ],
      "metadata": {
        "id": "k0KyS3_zINRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking first view of final dataframe\n",
        "Final_df.head()"
      ],
      "metadata": {
        "id": "6l00JjmCloCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking information of merged dataframe\n",
        "Final_df.info()     "
      ],
      "metadata": {
        "id": "XrSU0y_xgaOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print all unique values\n",
        "get_all_unique_values(Final_df) "
      ],
      "metadata": {
        "id": "IoKrPPvtltGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking unique for country\n",
        "Final_df['Country'].unique() "
      ],
      "metadata": {
        "id": "kDrAwLpcrTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking minimum year\n",
        "Final_df['Year-Of-Publication'].min() "
      ],
      "metadata": {
        "id": "W3icqsfN5BjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking maximum year\n",
        "Final_df['Year-Of-Publication'].max() "
      ],
      "metadata": {
        "id": "WvBCDkiz40GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **User-ID:** a unique identifier for each user who has provided a book rating.\n",
        "* **Age:** the age of the user who provided the book rating.\n",
        "* **City:** the city where the user who provided the book rating lives.\n",
        "* **State:** the state or province where the user who provided the book rating lives.\n",
        "* **Country:** the country where the user who provided the book rating lives.\n",
        "* **ISBN:** a unique identifier for the book that was rated.\n",
        "* **Book-Rating:** the rating that the user provided for the book, on a scale from 1 to 10.\n",
        "* **Avg_Rating:** the average rating for the book across all users who have rated it.\n",
        "* **Book-Title:** the title of the book that was rated.\n",
        "* **Book-Author:** the author of the book that was rated.\n",
        "* **Year-Of-Publication:** the year in which the book was published.\n",
        "* **Publisher:** the publisher of the book that was rated.\n",
        "\n",
        "This dataset could be used for various analyses, such as identifying popular books or authors, understanding the distribution of book ratings, or recommending books to users based on their past ratings or demographic information."
      ],
      "metadata": {
        "id": "m95Et3PnIWfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Univariate**"
      ],
      "metadata": {
        "id": "h4Fp5XHtEXXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Distribution of Age and Explicit Rating**"
      ],
      "metadata": {
        "id": "z8VSV_WprTeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy of merged dataframe for EDA \n",
        "Eda_df = Final_df.copy()"
      ],
      "metadata": {
        "id": "9aZa5pZxrTeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking first 5 rows \n",
        "Eda_df.head()"
      ],
      "metadata": {
        "id": "vloNfpX4rTeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Age**"
      ],
      "metadata": {
        "id": "JN2JqKzDU6IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Distribtuion of age column\n",
        "sns.distplot(Eda_df.Age)\n",
        "plt.title('Age Distribution Plot')"
      ],
      "metadata": {
        "id": "uIYFbS-jrTeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of the Age**\n",
        "\n",
        "The distplot shows how many individuals in the dataset fall within each age range, with the x-axis representing the age ranges and the y-axis representing the frequency or density of individuals."
      ],
      "metadata": {
        "id": "9PZL1BX3SxD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data grouped into bins based on age ranges specified in the 'bins' parameter.\n",
        "\n",
        "Eda_df.Age.hist(bins=[0, 10, 20, 30, 40, 50,60,70,80])\n",
        "plt.title('Age Distribution\\n')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GbToUJrcrTeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The most active users are among those in their 30–40s.**"
      ],
      "metadata": {
        "id": "ofEWcJzbrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ratings are very unevenly distributed, and the vast majority of ratings are 0 .As quoted in the description of the dataset - BX-Book-Ratings contains the book rating information. Ratings are either explicit, expressed on a scale from 1-10 higher values denoting higher appreciation, or implicit, expressed by 0.Hence segragating implicit and explict ratings datasets.**"
      ],
      "metadata": {
        "id": "QS5ujlTtrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "--SElxSFrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are a great way to visualize the distribution of a continuous variable like age. \n",
        "\n",
        "They group the data into bins or intervals and display the number of observations that fall into each bin, allowing us to see patterns in the data such as the shape of the distribution, the range of values, and the presence of any outliers or gaps.\n",
        "\n",
        "In this case, the 'Age Distribution Plot' and the 'Age Distribution' plots both use histograms to show the distribution of ages in the dataset. \n",
        "The second plot has more control over the binning of the data, allowing for more specific age ranges to be displayed."
      ],
      "metadata": {
        "id": "c2Pg_fMPrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "7ttkwtXMrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can provide insights into potential subgroups within the dataset.\n",
        "\n",
        "* The age distribution is roughly symmetrical, skewed to the left or right, or bimodal.\n",
        "\n",
        "* Range of ages in the dataset, from the youngest to the oldest individuals. This can help identify any outliers or gaps in the data.\n",
        "\n",
        "* It show which age ranges have the highest frequency of individuals."
      ],
      "metadata": {
        "id": "HpUAnXiJrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "8kl07-NgrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The potential positive or negative business impact of the insights gained from the age distribution plot will depend on the specific business context and goals.\n",
        "\n",
        "**For example**, if the business is a toy company targeting children, the insight that the majority of individuals in the dataset are in the age range of 5-10 years could be a positive insight that could help the company target their marketing efforts towards that age range.\n",
        "\n",
        "As for specific insights that could lead to negative growth, if the age distribution plot reveals a significant outlier or gap in the data, such as a very small number of individuals in a key age range, this could indicate a potential issue with the market or target demographic that could impact business growth."
      ],
      "metadata": {
        "id": "CRcbQbBGrTeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Explicit Rating**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HLh9U4VBsDAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the ratings are distributed"
      ],
      "metadata": {
        "id": "R8e7_ekgEjLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=ratings_df_explicit , x='Book-Rating', palette='rocket_r')"
      ],
      "metadata": {
        "id": "psKUvRe6sDAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart shows the number of times each rating value appears in the dataset, with each rating value represented by a separate bar. \n",
        "The x-axis represents the possible rating values (1-10), while the y-axis represents the frequency count of each rating value."
      ],
      "metadata": {
        "id": "UchbGKesYt8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most books are rated 8, if we exclude the books, which are implicitly rated."
      ],
      "metadata": {
        "id": "7v_WX3XusDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "REnNCy4msDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A countplot, was chosen because it is an effective way to visualize the frequency count of categorical data, In this case, the ratings given to books.\n",
        "\n",
        "It can help in identifying patterns and trends in the data."
      ],
      "metadata": {
        "id": "1Yg3DmR1sDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "sr-ZDWZhsDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the chart suggest that readers in the dataset generally have a positive opinion of the books they read, but they are not likely to give extreme ratings (either very high or very low).\n",
        "\n",
        "* The chart visualizes the frequency count of each rating given to books.\n",
        "We can see that the majority of ratings fall between 7-10, indicating that readers generally have a positive opinion of the books they read.\n",
        "\n",
        "* The number of ratings in the 1-3 range is significantly lower, indicating that readers are less likely to give very low ratings to books. \n",
        "\n",
        "* The chart reveals a peak in the frequency count of 8, indicating that this rating is the most common rating given to books in the dataset. This could suggest that readers have a tendency to rate books positively, but not overwhelmingly so.\n",
        "\n",
        "This information could be useful for businesses that rely on book reviews to assess customer satisfaction and identify areas for improvement."
      ],
      "metadata": {
        "id": "lVUVCTVQsDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "gpheOmq3sDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the chart could potentially help businesses that rely on book reviews to assess customer satisfaction and improve their products or services. \n",
        "\n",
        "The fact that readers in the dataset generally have a positive opinion of the books they read could be encouraging for publishers and authors, as it suggests that readers are more likely to recommend their books to others.\n",
        "\n",
        "The insights gained from the chart could be useful for businesses in the book industry, they should be used in conjunction with other data sources and market research to make informed decisions."
      ],
      "metadata": {
        "id": "iUCxZMM6sDAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most books are rated 8, if we exclude the books, which are implicitly rated."
      ],
      "metadata": {
        "id": "mn0tg6VG3IgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bivariate**"
      ],
      "metadata": {
        "id": "JVyNjioAjLlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**To analyze the distribution of book ratings across Top 10 Countries and test for differences between Top Countries.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNp227UfjeDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the top 10 countries based on the number of ratings\n",
        "top_countries = Eda_df[\"Country\"].value_counts().head(10).index.tolist()\n",
        "\n",
        "# Filter the data to include only the top 10 countries\n",
        "df_top_countries = Eda_df[Eda_df[\"Country\"].isin(top_countries)]\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Create a box plot for each of the top countries\n",
        "sns.set(style=\"whitegrid\")\n",
        "sns.boxplot(x=\"Country\", y=\"Book-Rating\", data=df_top_countries, \n",
        "            order=top_countries, palette=\"Set3\", \n",
        "            width=0.5, fliersize=3, linewidth=1,\n",
        "            saturation=0.8)\n",
        "\n",
        "# Test for differences between the top countries\n",
        "grouped_data = [df_top_countries[df_top_countries[\"Country\"] == c][\"Book-Rating\"].values for c in top_countries]\n",
        "statistic, p_value = stats.kruskal(*grouped_data)\n",
        "\n",
        "print(\"Kruskal-Wallis H test:\")\n",
        "print(f\"Statistic: {statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "aClZKA0U7aw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment is testing for differences between the book rating distributions of the top 10 countries. It uses the Kruskal-Wallis H test, which is a non-parametric test used to compare three or more groups of data that do not follow a normal distribution. The test is used to determine whether there is a statistically significant difference between the median of the book rating distributions of the top 10 countries.\n",
        "\n",
        "The code first filters the data to include only the top 10 countries based on the number of ratings, then creates a box plot for each of these countries to visualize the distribution of book ratings. After that, it calculates the Kruskal-Wallis H statistic and the associated p-value to test for differences between the book rating distributions of the top 10 countries.\n",
        "\n",
        "Finally, the code prints out the Kruskal-Wallis H test results, including the H statistic and the p-value. A significant p-value suggests that there is a difference between the book rating distributions of the top 10 countries, while a non-significant p-value suggests that there is no significant difference."
      ],
      "metadata": {
        "id": "Ik1jhoEyhUMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "i48Ty0QPstRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart used in the code is a box plot, which is a useful visualization for showing the distribution of data and identifying outliers. In this case, it is used to compare the distribution of book ratings across the top 10 countries in the dataset. Each box represents the interquartile range of the data, with the median represented by a horizontal line inside the box. The whiskers show the range of the data, and any outliers are represented as individual points.\n",
        "\n",
        "The box plot is particularly useful for comparing the distribution of data between different groups, in this case, the top 10 countries. By comparing the position and shape of the boxes, we can quickly see whether there are any differences in the distribution of book ratings between the countries. Additionally, the Kruskal-Wallis H test is used to test for differences between the countries, providing a statistical assessment of any observed differences."
      ],
      "metadata": {
        "id": "cKgnCs0nhcj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r0TCYaCzstRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot chart displays the distribution of book ratings across the top 10 countries. Each box represents the interquartile range (IQR) of the data, with the median represented by the line inside the box. The whiskers show the range of the data, with outliers represented by dots.\n",
        "\n",
        "From the chart, we can see that the distribution of book ratings varies across the top 10 countries. The highest median rating is observed in the United States, followed by Canada and the United Kingdom. The distribution of ratings in the United States, Canada, and the United Kingdom are also relatively narrow, with the majority of ratings falling within the interquartile range.\n",
        "\n",
        "In contrast, some countries, such as Germany and Spain, have a wider distribution of ratings, indicating a more diverse range of opinions on the books. Additionally, the median rating in some countries, such as Germany, is lower than in others, indicating that readers in these countries may be more critical or have different tastes in books.\n",
        "\n",
        "The Kruskal-Wallis H test shows that there is a statistically significant difference in book ratings between the top 10 countries. This suggests that the country of origin of the reader may play a role in determining their book rating.\n",
        "\n",
        "Overall, the chart provides insights into the distribution of book ratings across the top 10 countries, which can be useful for publishers, authors, and marketers looking to understand the preferences of readers in different countries."
      ],
      "metadata": {
        "id": "-tnIM9PHhjkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "6rolBaY0stRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the analysis of the distribution of book ratings across top 10 countries can potentially lead to a positive business impact for a company in the book industry. The insights can help companies understand which countries are the most important markets for their products, and which countries may need more attention in terms of marketing and distribution.\n",
        "\n",
        "For example, if the analysis shows that a particular country has a high number of book ratings and high average ratings, it could indicate that this country is a key market for the company, and that there is potential for growth in that market. Conversely, if the analysis shows that a particular country has a low number of book ratings and low average ratings, it could indicate that this market may not be a profitable one for the company, and that resources may be better allocated elsewhere.\n",
        "\n",
        "However, it is also possible that the insights gained from the analysis could lead to negative growth if not properly interpreted or acted upon. For example, if a company assumes that a market is not profitable based solely on low book ratings, it may miss opportunities to reach new customers or to improve its products for that market. Similarly, if a company focuses all its attention on the top markets without considering other factors such as cultural differences or competition, it may fail to penetrate those markets effectively.\n",
        "\n",
        "Therefore, it is important to use the insights gained from the analysis as a starting point for further research and strategic planning, rather than as definitive conclusions about the profitability of a particular market or product. Companies should also consider other factors such as customer feedback, market trends, and competitive analysis when making business decisions based on the insights gained from the data analysis."
      ],
      "metadata": {
        "id": "YNece4sihqfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**List of publishers whose books tend to receive higher ratings.**"
      ],
      "metadata": {
        "id": "7fWiMWu362Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the average rating for each publisher\n",
        "publisher_ratings = Eda_df.groupby('Publisher')['Book-Rating'].mean()\n",
        "\n",
        "# Get the top 10 publishers with the highest average rating\n",
        "top_publishers = publisher_ratings.nlargest(10)\n",
        "\n",
        "# Create a bar chart of the top publishers and their average ratings\n",
        "plt.bar(top_publishers.index, top_publishers.values,color=['#ff9966'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Top 10 Publishers by Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bWOe2DISY5uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "u0lvd2GHs9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart was chosen because it is an effective way to visualize and compare the average ratings of different publishers. The chart shows each publisher as a separate bar, with the height of each bar representing the average rating for that publisher. By comparing the heights of the bars, it is easy to see which publishers have the highest average ratings."
      ],
      "metadata": {
        "id": "W73bp19Rs9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "V3ZMkWjTs9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 10 publishers with the highest average rating.** \n",
        "\n",
        "The publisher with the highest average rating is 'HarperFlamingo Canada' with an average rating of around 8.0. This means that books published by this publisher were generally well-received by the readers.\n",
        "\n",
        "The second highest-rated publisher is 'Bloomsbury Publishing PLC', followed by 'Harcourt', 'Viking Books', 'Scholastic', 'Houghton Mifflin Company', 'Hyperion Books', 'Knopf', 'Doubleday' and 'Penguin Books'. All of these publishers have average ratings between 7.5 and 7.9.\n",
        "\n",
        "We can conclude that books published by these top-rated publishers are likely to be of high quality and well-regarded by readers. \n",
        "This can be useful information for book lovers who are looking for new books to read, as they can use this chart to identify publishers that consistently produce high-quality books."
      ],
      "metadata": {
        "id": "_30WpQr3s9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3hzqtQIes9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a positive business impact** for publishers in the book industry. Publishers with high average ratings, such as 'HarperFlamingo Canada', could use this information to promote their brand and books to potential readers. By highlighting their high ratings, they could potentially attract new readers and generate more sales.\n",
        "\n",
        "If a publisher has a low average rating compared to their competitors, it could lead to **negative growth** as readers may be less likely to purchase books from that publisher. \n",
        "\n",
        "**The insights gained** from this chart could be useful for publishers in making strategic decisions about their business and marketing efforts. By understanding which publishers are highly regarded by readers, they could potentially increase sales and create a positive impact on their business. Conversely, publishers with lower ratings may need to make changes in order to improve their standing among readers and avoid negative growth."
      ],
      "metadata": {
        "id": "8ZziPQUrs9xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**List of authors whose books tend to receive higher ratings.**"
      ],
      "metadata": {
        "id": "qIxMSzuAfMTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the average rating for each author\n",
        "author_ratings = Eda_df.groupby('Book-Author')['Book-Rating'].mean()\n",
        "\n",
        "# Get the top 10 authors with the highest average rating\n",
        "top_authors = author_ratings.nlargest(10)\n",
        "\n",
        "# Create a bar chart of the top authors and their average ratings\n",
        "plt.bar(top_authors.index, top_authors.values,color=['#669999'])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Average Rating')\n",
        "plt.title('Top 10 Authors by Average Rating')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8BQQnFqYdZuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "DQc2H_TxtOmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart is a suitable for visualizing the average rating of each author, as it allows us to compare the ratings of multiple authors at once. The height of each bar represents the average rating of the corresponding author, making it easy to identify the authors with the highest ratings. \n",
        "\n",
        "The average rating of each author, the bar chart effectively displays this information and allows us to easily identify the top-rated authors. "
      ],
      "metadata": {
        "id": "RfXbNe08tOmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "BOMvoBQ9tOmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 authors with the highest average rating. \n",
        "The insights gained from this chart include:\n",
        "* The highest-rated author in the dataset is J.K. Rowling, with an average rating of 8.75.\n",
        "* The top 10 authors have average ratings ranging from 7.94 to 8.75, indicating that they are all highly rated by readers.\n",
        "* The majority of the top-rated authors are known for writing fiction, with only one non-fiction author making the list.\n",
        "* There is a range of publication dates among the top-rated authors, suggesting that books from different time periods can still be popular with readers.\n",
        "\n",
        "For example, publishers may choose to work with the top-rated authors on future projects or to focus on promoting their books more heavily."
      ],
      "metadata": {
        "id": "zUMqZHB2tOmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "5q5UJI-OtOmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the chart of the top 10 authors by average rating can help create a positive business impact in the publishing industry. \n",
        "Publishers can use this information to identify highly-rated authors to work with and to guide their decisions when it comes to promoting books. Knowing which authors are popular with readers can also help publishers make more informed decisions about what genres or types of books to invest in.\n",
        "\n",
        "There are no insights from this chart that directly lead to negative growth, there is always the potential for misinterpreting the data or making poor business decisions based on incomplete information. "
      ],
      "metadata": {
        "id": "dVglrvPOtOmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pzc6xbHNKUxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Top 10 Publisher with Most Books Published**"
      ],
      "metadata": {
        "id": "WcReZER_NAg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of books by publisher\n",
        "publisher_counts = Eda_df[\"Publisher\"].value_counts().head(10)\n",
        "\n",
        "# Create bar chart\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=publisher_counts.values, y=publisher_counts.index, palette=\"inferno\")\n",
        "plt.title(\"Top 10 Publishers with Most Books\")\n",
        "plt.xlabel(\"Total Number of Books\")\n",
        "plt.ylabel(\"Publisher Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o1lbJjAf0kyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gfxMEx890kyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I picked a bar chart because it effectively shows the comparison between the number of books published by different publishers."
      ],
      "metadata": {
        "id": "ygHUlbKu0kyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "bl_RJFUP0kyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Harlequin is the Publisher with most no of books published followed by Silhouette"
      ],
      "metadata": {
        "id": "1XIc3OZo0kyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "g0okCeQq0kyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* this insight can help businesses understand which genres and authors are popular among readers, as publishers tend to specialize in certain genres or types of books. This can inform their decision-making when it comes to acquiring new titles and authors, and help them tailor their marketing campaigns to specific audiences"
      ],
      "metadata": {
        "id": "8sCsyhPV0kyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Top 10 Book Authors with Most Books Written**"
      ],
      "metadata": {
        "id": "8d3rwl0iN89m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of books by publisher\n",
        "publisher_counts = books_df[\"Book-Author\"].value_counts().head(10)\n",
        "\n",
        "# Create bar chart\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=publisher_counts.values, y=publisher_counts.index, palette=\"inferno\")\n",
        "plt.title(\"Top 10  Book Authors with Most Books\")\n",
        "plt.xlabel(\"Total Number of Books\")\n",
        "plt.ylabel(\" Book Authors Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ggsWMx-B0kyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "kdXgwbh70kyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I selected this chart because it effectively visualizes the number of books published by each author, allowing us to quickly see which authors have published the most books. The bar chart is a commonly used chart type for visualizing numerical data, and it is particularly effective for showing comparisons between categories"
      ],
      "metadata": {
        "id": "JLeJZARG0kyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "fxb-b5Fy0kyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agatha Christie is the Author with most no of books Published  followed by William Shakespeare and Stephen king."
      ],
      "metadata": {
        "id": "GaKa2vBJ0kyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "nCH4iRkU0kyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* knowing which authors are most popular can also help publishers and booksellers identify trends in the market and adjust their strategies accordingly. "
      ],
      "metadata": {
        "id": "m8FvsLU50kyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Top 5 Years with Most Books Published**"
      ],
      "metadata": {
        "id": "K_Vhi-8RUijH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of books published per year\n",
        "year_counts = Eda_df[\"Year-Of-Publication\"].value_counts()\n",
        "\n",
        "# Sort the counts by year\n",
        "year_counts = year_counts.sort_index()\n",
        "\n",
        "# Get the top 5 years\n",
        "top_years = year_counts.nlargest(5)\n",
        "\n",
        "# Create a bar chart of the top 5 years\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_years.index, y=top_years.values, palette=\"inferno\")\n",
        "plt.title(\"Top 5 Years with Most Books Published\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Books Published\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RjU8i_ct0kyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "3DdoFTfa0kyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " * A vertical bar chart, is a good choice for visualizing the top 5 years with the most books published because it allows us to easily compare the number of books published across different years"
      ],
      "metadata": {
        "id": "KjVX3EF40kyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ivZx-0Qp0kyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The top 5 years with the most books published are 1996, 1999, 2000, 2001, and 2002\n"
      ],
      "metadata": {
        "id": "6hzzbcQ_0kyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "im7L1u0t0kyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* publishers can use this information to identify trends and patterns in the industry, as well as to assess the competitiveness of certain years. Bookstores and online retailers can also use this information to optimize their inventory and make better decisions about which books to stock\n"
      ],
      "metadata": {
        "id": "KMlRLVaP0kyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multivariate**"
      ],
      "metadata": {
        "id": "GZ_NGGye63gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Ratings of popular books compare to those of less popular books, and does this vary by age group**"
      ],
      "metadata": {
        "id": "C0IcDpoDwiFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column for the age group based on the age of the user\n",
        "def get_age_group(age):  \n",
        "    if age < 18:\n",
        "        return 'Under 18'\n",
        "    elif age < 30:\n",
        "        return '18-29'\n",
        "    elif age < 40:\n",
        "        return '30-39'\n",
        "    elif age < 50:\n",
        "        return '40-49'\n",
        "    elif age < 60:\n",
        "        return '50-59'\n",
        "    else:\n",
        "        return '60+'\n",
        "# Add Age Group column in Popularity_df\n",
        "Eda_df['Age Group'] = Eda_df['Age'].apply(get_age_group)  "
      ],
      "metadata": {
        "id": "UQYKt3vmtm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating sum\n",
        "Eda_df['Total_No_Of_Users_Rated']=ratings_df_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "9Ukq-B8Ftm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define popularity based on total number of users who rated the book\n",
        "Eda_df['Popularity'] = Eda_df['Total_No_Of_Users_Rated'].apply(lambda x: 'Popular' if x > 50 else 'Less Popular')  "
      ],
      "metadata": {
        "id": "Msj9bFsgtm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by popularity and get the average rating for each group\n",
        "popularity_ratings = Eda_df.groupby('Popularity')['Book-Rating'].mean()\n",
        "popularity_ratings   "
      ],
      "metadata": {
        "id": "PdPl0lNstm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by popularity and age group and get the average rating for each group\n",
        "popularity_age_ratings = Eda_df.groupby(['Popularity', 'Age Group'])['Avg_Rating'].mean().reset_index() "
      ],
      "metadata": {
        "id": "zd6BvDGPtm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) \n",
        "\n",
        "# Create the bar chart of popularity ratings\n",
        "sns.barplot(x='Popularity', y='Avg_Rating', data=popularity_age_ratings, ax=ax1)\n",
        "ax1.set_ylabel('Average Rating')\n",
        "ax1.set_title('Average Rating by Book Popularity',fontsize=17) \n",
        "\n",
        "# Create the box plot of the average ratings by age group\n",
        "sns.boxplot(x='Age Group', y='Avg_Rating', hue='Popularity', data=Eda_df, ax=ax2)\n",
        "ax2.set_title('Distribution of Ratings by Age Group and Book Popularity',fontsize=17)\n",
        "ax2.set_xlabel('Age Group')\n",
        "ax2.set_ylabel('Book Rating')\n",
        "# Remove the legend box\n",
        "ax2.legend_.remove()\n",
        "# Adjust the spacing between the subplots\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gVKsrAfTtm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ZpXryQActm2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The boxplot was chosen because it effectively displays the relationship between book popularity, age group, and average rating. \n",
        "The left subplot(barplot) shows the average rating of popular and less popular books, while the right subplot displays the distribution of book ratings across different age groups and popularity categories. The combination of the two subplots provides a comprehensive view of how book popularity and age group affect the average rating."
      ],
      "metadata": {
        "id": "vAfbL6Hrtm2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "EwkQNrphtm2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first one shows the average rating of books grouped by their popularity. \n",
        "The second subplot shows the distribution of book ratings across age groups and popularity. \n",
        "Here are some insights that can be gained from the chart:\n",
        "\n",
        "* Books that are rated by a large number of users tend to have higher average ratings compared to less popular books.\n",
        "* Users in the age group of 18-29 have a higher tendency to rate books with lower ratings compared to other age groups.\n",
        "* Books that are rated by a large number of users tend to have lower variability in ratings compared to less popular books.\n",
        "* Users in the age group of 50-59 tend to rate books more positively compared to other age groups, regardless of the book's popularity.\n",
        "\n",
        "These insights can help businesses in the book industry to tailor their marketing and promotion strategies for different age groups and popularity levels of books. \n",
        "**For less popular books,** businesses can target age groups with a higher tendency to rate books positively, such as users in the age group of 50-59. \n",
        "**For popular books,** businesses can focus on targeting a wider audience to maximize their exposure and potentially increase their ratings."
      ],
      "metadata": {
        "id": "KbBqTpO3tm2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "zWJzzDeGtm2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a positive business impact**. This insight provides an understanding of the average ratings by book popularity and age group, which can be useful for publishers in identifying the target audience for their books. \n",
        "They can use this information to create marketing campaigns that cater to the specific age group and promote their popular books. \n",
        "Also, help in identifying the age groups that are more likely to rate books highly, which can help publishers in producing books that cater to the preferences of these age groups.\n",
        "\n",
        "**There are no insights lead to negative growth**. This insights does not provide any information that could potentially harm the business or lead to negative growth."
      ],
      "metadata": {
        "id": "4LoRSFqStm2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. ML Model Implementation***"
      ],
      "metadata": {
        "id": "LsM9Dex3MSsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "ckJ0pJVrMSsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Content Based Filtering** "
      ],
      "metadata": {
        "id": "ZnmJt5qDNscX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check final df information \n",
        "Final_df.info() "
      ],
      "metadata": {
        "id": "oYg7tJFXu8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating copy of final df for content based filtering\n",
        "Content_based_df = Final_df.copy()\n",
        "# Checking first view \n",
        "Content_based_df.head() "
      ],
      "metadata": {
        "id": "Syg1Iu_zu8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Python function that takes a book title as input &  returns a table of recommended books based on the author and publisher of the input book.\n",
        "          \n",
        "def content_based_recommender_table(book_title):\n",
        "    # Convert the input book title to a string type\n",
        "    book_title = str(book_title) \n",
        "    # Check if the input book title is in the dataset  \n",
        "    if book_title in Content_based_df['Book-Title'].values: \n",
        "        # Count the number of times each book title appears in the dataset  \n",
        "        rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts()) \n",
        "        # Get the book titles that appear less than or equal to 100 times  \n",
        "        rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index \n",
        "        # Get the subset of the dataset that only contains book titles that appear more than 100 times         \n",
        "        common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]  \n",
        "        \n",
        "        # If the input book title appears less than or equal to 100 times in the dataset\n",
        "        if book_title in rare_books:    \n",
        "            # Randomly select two book titles from the common_books dataset\n",
        "            random = pd.Series(common_books['Book-Title'].unique()).sample(2).values    \n",
        "            print('There are no recommendations for this book')\n",
        "            print('Try: \\n')\n",
        "            print('{}'.format(random[0]),'\\n')\n",
        "            print('{}'.format(random[1]),'\\n')\n",
        "        # If the input book title appears more than 100 times in the dataset\n",
        "        else:      \n",
        "            # Drop any duplicates of book titles in the common_books dataset\n",
        "            common_books = common_books.drop_duplicates(subset=['Book-Title']) \n",
        "            # Reset the index of the common_books dataset  \n",
        "            common_books.reset_index(inplace= True) \n",
        "            # Create a new index column with consecutive integers                             \n",
        "            common_books['index'] = [i for i in range(common_books.shape[0])]    \n",
        "            \n",
        "            # Get the columns to be used for computing cosine similarity\n",
        "            target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "            # Combine the target columns into a single string for each book title               \n",
        "            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]  \n",
        "\n",
        "             # Initialize the CountVectorizer object    \n",
        "            cv = CountVectorizer() \n",
        "            # Create a count matrix of the combined features using CountVectorizer        \n",
        "            count_matrix = cv.fit_transform(common_books['combined_features']) \n",
        "            # Compute the cosine similarity matrix   \n",
        "            cosine_sim = cosine_similarity(count_matrix)\n",
        "            # Get the index of the input book title in the common_books dataset                          \n",
        "            index = common_books[common_books['Book-Title'] == book_title]['index'].values[0] \n",
        "            # Get the cosine similarity scores of the input book title with all other book titles  \n",
        "            sim_books = list(enumerate(cosine_sim[index])) \n",
        "            # Sort the cosine similarity scores in descending order and select the top 5 books with the highest scores, excluding the input book title itself        \n",
        "            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:6]  \n",
        "                                    \n",
        "            # Create a empty list for books\n",
        "            books = []\n",
        "            for i in range(len(sorted_sim_books)):\n",
        "                # Get the book titles that have the indices that correspond to the top 5 cosine similarity scores\n",
        "                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]])  \n",
        "            # Concatenate the selected book titles into a single output table\n",
        "            output_table = pd.concat(books)   \n",
        "\n",
        "            # Drop the index and combined_features columns\n",
        "            output_table.drop(columns=['index', 'combined_features'], inplace=True)\n",
        "           \n",
        "            # Reset the index to be consecutive integers starting from 1\n",
        "            output_table.index = [i+1 for i in range(output_table.shape[0])]         \n",
        "            \n",
        "            # Print the recommendation based on author & publisher\n",
        "            print('Recommendations for \"{}\" based on Author and Publisher:'.format(book_title))\n",
        "            # Print the output table \n",
        "            print(output_table[['Book-Title', 'Book-Author', 'Publisher']])\n",
        "            \n",
        "        return\n",
        "    # If input book does not have any recommended book then it will print else statement \n",
        "    else:\n",
        "        \n",
        "        print('Can\\'t find book in dataset, please check spelling')\n"
      ],
      "metadata": {
        "id": "Ebxj3e65_Twq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling function for book recommendation \n",
        "content_based_recommender_table(\"Harry Potter and the Sorcerer's Stone (Book 1)\")"
      ],
      "metadata": {
        "id": "0W1S9Vdcu8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content-based filtering recommender system uses the CountVectorizer and cosine similarity algorithm to recommend books based on the similarity of their author and publisher with the input book. The CountVectorizer converts the combined features (author and publisher) of each book into a matrix of token counts. The cosine similarity algorithm is then used to calculate the similarity between the input book and all other books in the dataset based on their token counts. The top 5 books with the highest similarity scores are recommended to the user."
      ],
      "metadata": {
        "id": "5wpA6Oe37olu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Content Based Recommender Table function breaked into individual steps.** \n",
        "##**The purpose is only for easy understanding to who is use this function.** "
      ],
      "metadata": {
        "id": "uZpmnDf6M_LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input book title to a string type\n",
        "Content_based_df['Book-Title'] = Content_based_df['Book-Title'].astype(str) "
      ],
      "metadata": {
        "id": "xqG3CFOjby4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of times each book title appears in the dataset\n",
        "rating_counts = pd.DataFrame(Content_based_df['Book-Title'].value_counts())\n",
        "rating_counts "
      ],
      "metadata": {
        "id": "CdkvWHd_eD4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the book titles that appear less than or equal to 100 times\n",
        "rare_books = rating_counts[rating_counts['Book-Title'] <= 100].index\n",
        "rare_books "
      ],
      "metadata": {
        "id": "1ePgWuGzeW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the subset of the dataset that only contains book titles that appear more than 100 times\n",
        "common_books = Content_based_df[~Content_based_df['Book-Title'].isin(rare_books)]\n",
        "common_books "
      ],
      "metadata": {
        "id": "aCG7_KuyelJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Randomly select two book titles from the common_books dataset\n",
        "random = pd.Series(common_books['Book-Title'].unique()).sample(2).values\n",
        "random "
      ],
      "metadata": {
        "id": "rMiJo6dve7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any duplicates of book titles in the common_books dataset\n",
        "common_books = common_books.drop_duplicates(subset=['Book-Title'])\n",
        "common_books "
      ],
      "metadata": {
        "id": "sl7UCFL-f_HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index of the common_books dataset\n",
        "common_books.reset_index(inplace= True) "
      ],
      "metadata": {
        "id": "JREHwlzmg4y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new index column with consecutive integers\n",
        "common_books['index'] = [i for i in range(common_books.shape[0])] "
      ],
      "metadata": {
        "id": "wsgiU670gJEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the columns to be used for computing cosine similarity\n",
        "target_cols = ['Book-Title','Book-Author','Publisher']\n",
        "# Combine the target columns into a single string for each book title\n",
        "common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])] "
      ],
      "metadata": {
        "id": "WNxutJvMf7rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_books "
      ],
      "metadata": {
        "id": "jvzGQqdFhEcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the CountVectorizer object\n",
        "cv = CountVectorizer()\n",
        "# Create a count matrix of the combined features using CountVectorizer\n",
        "count_matrix = cv.fit_transform(common_books['combined_features']) "
      ],
      "metadata": {
        "id": "uY8Sh5ERhFnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv"
      ],
      "metadata": {
        "id": "6fMnrf0f4S3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_matrix"
      ],
      "metadata": {
        "id": "eYR19szu4Rwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(count_matrix)\n",
        "cosine_sim "
      ],
      "metadata": {
        "id": "6xjoH8jlhFNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For user input\n",
        "book_title = input(\"Enter a book title: \")"
      ],
      "metadata": {
        "id": "0zrLyzFeNipG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if book_title not in Content_based_df['Book-Title'].values:\n",
        "    print(\"Book title not found in dataset\")\n",
        "    try:\n",
        "        sys.exit()\n",
        "    except SystemExit:\n",
        "        pass \n",
        " "
      ],
      "metadata": {
        "id": "XQ4pZKFiK3xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of the input book title in the common_books dataset\n",
        "index = common_books[common_books['Book-Title'] == book_title]['index'].values[0]\n",
        "# Get the cosine similarity scores of the input book title with all other book titles\n",
        "sim_books = list(enumerate(cosine_sim[index]))  "
      ],
      "metadata": {
        "id": "D6D--PCqjTZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the cosine similarity scores in descending order and select the top 5 books with the highest scores, excluding the input book title itself\n",
        "sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
        "                                      reverse=True)[1:6]  \n",
        "sorted_sim_books  "
      ],
      "metadata": {
        "id": "BZGHQF__jZsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a empty list for books\n",
        "books = [] \n",
        "for i in range(len(sorted_sim_books)):\n",
        "    # Get the book titles that have the indices that correspond to the top 5 cosine similarity scores\n",
        "    books.append(common_books[common_books['index'] == sorted_sim_books[i][0]])\n",
        "# Concatenate the selected book titles into a single output table\n",
        "output_table = pd.concat(books)\n",
        "# Drop the index and combined_features columns\n",
        "output_table.drop(columns=['index', 'combined_features'], inplace=True)\n",
        "# Reset the index to be consecutive integers starting from 1\n",
        "output_table.index = [i+1 for i in range(output_table.shape[0])]\n",
        "# Print the recommendation based on author & publisher       \n",
        "print('Recommendations for \"{}\" based on Author and Publisher:'.format(book_title))\n",
        "# Print the output table\n",
        "print(output_table[['Book-Title', 'Book-Author', 'Publisher']]) "
      ],
      "metadata": {
        "id": "_bQNKweQi2ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the File\n",
        "# Importing pickle module\n",
        "import pickle"
      ],
      "metadata": {
        "id": "qY_af9Ss4csY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "with open('recommend.pkl', 'wb') as f:\n",
        "    pickle.dump(content_based_recommender_table, f)\n",
        "\n",
        "with open('counter_vector.pkl', 'wb') as f:\n",
        "    pickle.dump(cv, f)\n",
        "     \n",
        "with open('count_matrix.pkl', 'wb') as f:\n",
        "    pickle.dump(count_matrix, f)\n",
        "\n",
        "# Saving the dataframe in dictionary format\n",
        "with open('content_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(Content_based_df.to_dict(), f)\n",
        "\n",
        "#cosine_sim\n",
        "with open('cosine_similarity.pkl', 'wb') as f:\n",
        "    pickle.dump(cosine_sim, f)\n",
        "     "
      ],
      "metadata": {
        "id": "uncdFl-H4pkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading pickle files to local machine for deployment\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download('content_dict.pkl')\n",
        "# files.download('counter_vector.pkl')\n",
        "# files.download('count_matrix.pkl')\n",
        "# files.download('cosine_similarity.pkl')"
      ],
      "metadata": {
        "id": "XH0661kj5w25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the  graphs and information, several insights can be drawn for the book recommendation system:\n",
        "\n",
        "- **Demographic data**: The age distribution of users is roughly symmetrical with a peak in the middle age range. This can help identify any outliers or gaps in the data. Furthermore, the majority of users are from the United States and Canada.\n",
        "\n",
        "- **Ratings**: The majority of book ratings fall between 7-10, indicating that readers generally have a positive opinion of the books they read. The number of ratings in the 1-3 range is significantly lower, indicating that readers are less likely to give very low ratings to books.\n",
        "\n",
        "- **Publishers and authors**: Harlequin is the publisher with the most books published, followed by Silhouette. Agatha Christie is the author with the most books published, followed by William Shakespeare and Stephen King. This information can be useful in recommending books by popular publishers or authors to users.\n",
        "\n",
        "- **Bar chart showing the average rating by country and book for the top 5 countries with top 5 books by average rating**: We have identified the top 5 most highly rated books by country. \"Cunt: A declaration of independence\" received a rating of 10 in New Zealand and 8 in the USA. \"Intelligence Wars\" received a rating of 10 in the \"Other\" category. \"Naked Desires\" received a rating of 10 in the USA. \"The Great Adventures of Sherlock Holmes\" received a rating of 10 in Ireland. Lastly, \"The Great American Bake Sale\" received a rating of 10 in the USA.\n",
        "\n",
        "- **Publishing trends**: The top 5 years with the most books published are 1999, 2000, 2001,2002 and 2003. This can help identify popular books from those years and recommend them to users.\n",
        "\n",
        "- **User preferences**: The box plot chart displays the distribution of book ratings across the top 10 countries. From the chart, we can see that the distribution of book ratings varies across different countries. Therefore, by analyzing the preferences of users from different countries, the recommendation system can provide personalized book recommendations to users based on their preferences.\n",
        "\n",
        "Overall, by using the information from the provided dataset, the book recommendation system can provide personalized recommendations to users based on their preferences, demographics, and popular books from different publishers and authors.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JmkDfvFAOD_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ML model implemented for the book recommendation system have their own strengths and limitations.**\n",
        "\n",
        "- **The Content-Based Filtering model** is useful when we have a good understanding of user preferences and the content of the items. It is a personalized approach that provides recommendations based on the user's past interactions and preferences. However, it has limitations when it comes to recommending items outside the user's past interactions and preferences.\n",
        "\n",
        "Overall, the book recommendation system can be improved further by exploring other recommendation techniques like Matrix Factorization, Deep Learning models, and Reinforcement Learning. The ultimate goal of the book recommendation system is to provide highly personalized and accurate recommendations to the users, and these models provide a good starting point to achieve this goal."
      ],
      "metadata": {
        "id": "VGnagPD3kOHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}